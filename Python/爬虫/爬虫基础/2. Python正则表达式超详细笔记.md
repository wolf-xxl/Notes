
## 1. 正则表达式基础概念

### 1.1 什么是正则表达式
```python
"""
正则表达式（Regular Expression）是一种用于匹配和处理文本的强大工具
它使用特定的语法规则来描述字符串的模式，可以用于：
- 文本搜索和匹配
- 数据验证
- 文本替换
- 数据提取
"""

def regex_introduction():
    """
    正则表达式的基本概念：
    1. 模式（Pattern）：描述要匹配的文本规则
    2. 元字符（Metacharacters）：具有特殊含义的字符
    3. 字面量（Literals）：匹配自身的普通字符
    4. 字符类（Character Classes）：匹配一组字符中的任意一个
    """
    
    examples = {
        "简单匹配": "hello 匹配 'hello'",
        "字符类": "[aeiou] 匹配任意元音字母",
        "量词": "a+ 匹配一个或多个连续的a",
        "分组": "(abc)+ 匹配重复的'abc'"
    }
    
    return examples

print("正则表达式示例:")
for pattern, description in regex_introduction().items():
    print(f"  {pattern}: {description}")
# 输出:
# 正则表达式示例:
#   简单匹配: hello 匹配 'hello'
#   字符类: [aeiou] 匹配任意元音字母
#   量词: a+ 匹配一个或多个连续的a
#   分组: (abc)+ 匹配重复的'abc'
```

### 1.2 Python re模块简介
```python
import re  # 导入Python的正则表达式模块

def re_module_overview():
    """
    re模块提供的主要功能：
    1. 编译正则表达式
    2. 执行匹配操作
    3. 搜索和替换
    4. 字符串分割
    """
    
    # re模块的主要函数
    functions = [
        "re.compile() - 编译正则表达式模式",
        "re.match() - 从字符串开头匹配",
        "re.search() - 搜索整个字符串",
        "re.findall() - 找到所有匹配项",
        "re.finditer() - 返回匹配迭代器", 
        "re.sub() - 替换匹配项",
        "re.split() - 根据模式分割字符串"
    ]
    
    return functions

print("re模块主要函数:")
for func in re_module_overview():
    print(f"  {func}")
# 输出:
# re模块主要函数:
#   re.compile() - 编译正则表达式模式
#   re.match() - 从字符串开头匹配
#   re.search() - 搜索整个字符串
#   re.findall() - 找到所有匹配项
#   re.finditer() - 返回匹配迭代器
#   re.sub() - 替换匹配项
#   re.split() - 根据模式分割字符串
```

## 2. 基本匹配模式

### 2.1 字面量匹配
```python
import re

def literal_matching():
    """字面量匹配：直接匹配文本中的字符"""
    
    text = "Hello, my name is John. I live in New York."
    
    # 1. 简单字面量匹配
    pattern = "John"
    match = re.search(pattern, text)
    if match:
        print(f"1. 找到匹配: '{match.group()}'")  # 输出: 1. 找到匹配: 'John'
        print(f"   匹配位置: {match.start()} 到 {match.end()}")  # 输出: 匹配位置: 17 到 21
    else:
        print("1. 未找到匹配")
    
    # 2. 匹配特殊字符（需要转义）
    text_with_special = "Price: $100.00 + tax"
    pattern_special = r"\$100\.00"  # r前缀表示原始字符串，避免转义问题
    match_special = re.search(pattern_special, text_with_special)
    if match_special:
        print(f"2. 特殊字符匹配: '{match_special.group()}'")  # 输出: 2. 特殊字符匹配: '$100.00'
    
    # 3. 大小写敏感匹配
    pattern_case = "hello"
    match_case = re.search(pattern_case, text)  # 默认大小写敏感
    if match_case:
        print(f"3. 大小写敏感匹配: '{match_case.group()}'")
    else:
        print("3. 大小写敏感匹配: 未找到 'hello'")  # 输出: 3. 大小写敏感匹配: 未找到 'hello'
    
    # 4. 大小写不敏感匹配
    match_insensitive = re.search(pattern_case, text, re.IGNORECASE)
    if match_insensitive:
        print(f"4. 大小写不敏感匹配: '{match_insensitive.group()}'")  # 输出: 4. 大小写不敏感匹配: 'Hello'

literal_matching()
```

### 2.2 字符类和预定义字符类
```python
def character_classes():
    """字符类：匹配一组字符中的任意一个"""
    
    text = "The quick brown fox jumps over 123 lazy dogs."
    
    print("字符类匹配演示:")
    
    # 1. 自定义字符类
    pattern_vowels = r"[aeiou]"  # 匹配任意元音字母
    vowels = re.findall(pattern_vowels, text, re.IGNORECASE)
    print(f"1. 元音字母: {vowels}")  # 输出: 1. 元音字母: ['e', 'u', 'i', 'o', 'o', 'u', 'o', 'e', 'a', 'o']
    
    # 2. 字符范围
    pattern_digits = r"[0-9]"  # 匹配任意数字
    digits = re.findall(pattern_digits, text)
    print(f"2. 数字: {digits}")  # 输出: 2. 数字: ['1', '2', '3']
    
    # 3. 排除字符类
    pattern_non_vowels = r"[^aeiou\s\.]"  # 匹配非元音、非空白、非点号的字符
    non_vowels = re.findall(pattern_non_vowels, text, re.IGNORECASE)
    print(f"3. 非元音字符: {non_vowels[:10]}...")  # 输出: 3. 非元音字符: ['T', 'h', 'q', 'c', 'k', 'b', 'r', 'w', 'n', 'f']...
    
    # 4. 预定义字符类
    patterns = {
        r"\d": "数字 (等价于 [0-9])",
        r"\D": "非数字 (等价于 [^0-9])", 
        r"\w": "单词字符 (字母、数字、下划线)",
        r"\W": "非单词字符",
        r"\s": "空白字符 (空格、制表符、换行等)",
        r"\S": "非空白字符"
    }
    
    print("4. 预定义字符类:")
    for pattern, description in patterns.items():
        matches = re.findall(pattern, text)
        print(f"   {pattern} - {description}: {matches[:5]}...")

character_classes()
```

## 3. 量词和重复匹配

### 3.1 基本量词
```python
def quantifiers_demo():
    """量词：控制模式重复的次数"""
    
    text = "a ab abb abbb abbbb abbbbb"
    
    print("量词匹配演示:")
    
    # 测试数据
    test_cases = [
        (r"ab", "匹配 'ab'"),
        (r"ab?", "匹配 'a' 或 'ab' (0或1次)"),
        (r"ab*", "匹配 'a' 后面跟0个或多个 'b'"),
        (r"ab+", "匹配 'a' 后面跟1个或多个 'b'"),
        (r"ab{2}", "匹配 'a' 后面跟恰好2个 'b'"),
        (r"ab{2,}", "匹配 'a' 后面跟至少2个 'b'"),
        (r"ab{2,4}", "匹配 'a' 后面跟2到4个 'b'")
    ]
    
    for pattern, description in test_cases:
        matches = re.findall(pattern, text)
        print(f"  {pattern:10} - {description:30} → {matches}")

quantifiers_demo()
# 输出:
# 量词匹配演示:
#   ab         - 匹配 'ab'                          → ['ab', 'ab', 'ab', 'ab', 'ab', 'ab']
#   ab?        - 匹配 'a' 或 'ab' (0或1次)          → ['ab', 'ab', 'ab', 'ab', 'ab', 'ab']
#   ab*        - 匹配 'a' 后面跟0个或多个 'b'       → ['a', 'ab', 'abb', 'abbb', 'abbbb', 'abbbbb']
#   ab+        - 匹配 'a' 后面跟1个或多个 'b'       → ['ab', 'abb', 'abbb', 'abbbb', 'abbbbb']
#   ab{2}      - 匹配 'a' 后面跟恰好2个 'b'         → ['abb', 'abb', 'abb', 'abb', 'abb', 'abb']
#   ab{2,}     - 匹配 'a' 后面跟至少2个 'b'         → ['abb', 'abbb', 'abbbb', 'abbbbb']
#   ab{2,4}    - 匹配 'a' 后面跟2到4个 'b'          → ['abb', 'abbb', 'abbbb']
```

### 3.2 贪婪 vs 非贪婪匹配
```python
def greedy_vs_lazy():
    """贪婪匹配和非贪婪匹配的区别"""
    
    html_text = "<div>Content 1</div><div>Content 2</div><div>Content 3</div>"
    
    print("贪婪 vs 非贪婪匹配:")
    
    # 1. 贪婪匹配（默认）
    greedy_pattern = r"<div>.*</div>"
    greedy_match = re.search(greedy_pattern, html_text)
    if greedy_match:
        print(f"1. 贪婪匹配: '{greedy_match.group()}'")
        # 输出: 1. 贪婪匹配: '<div>Content 1</div><div>Content 2</div><div>Content 3</div>'
    
    # 2. 非贪婪匹配（在量词后加 ?）
    lazy_pattern = r"<div>.*?</div>"
    lazy_matches = re.findall(lazy_pattern, html_text)
    print(f"2. 非贪婪匹配: {lazy_matches}")
    # 输出: 2. 非贪婪匹配: ['<div>Content 1</div>', '<div>Content 2</div>', '<div>Content 3</div>']
    
    # 3. 实际应用示例
    email_text = "Names: John <john@email.com>, Jane <jane@email.com>"
    
    # 贪婪方式（错误）
    greedy_email = r"<.*>"
    greedy_emails = re.findall(greedy_email, email_text)
    print(f"3. 贪婪方式提取邮箱: {greedy_emails}")
    # 输出: 3. 贪婪方式提取邮箱: ['<john@email.com>, Jane <jane@email.com>']
    
    # 非贪婪方式（正确）
    lazy_email = r"<.*?>"
    lazy_emails = re.findall(lazy_email, email_text)
    print(f"4. 非贪婪方式提取邮箱: {lazy_emails}")
    # 输出: 4. 非贪婪方式提取邮箱: ['<john@email.com>', '<jane@email.com>']

greedy_vs_lazy()
```

## 4. 位置匹配和边界

### 4.1 字符串边界
```python
def anchors_and_boundaries():
    """锚点和边界匹配"""
    
    text = "cat category catfish concatenate"
    
    print("边界匹配演示:")
    
    # 1. 单词边界 \b
    word_boundary_pattern = r"\bcat\b"
    word_boundary_matches = re.findall(word_boundary_pattern, text)
    print(f"1. 单词边界 \\bcat\\b: {word_boundary_matches}")  # 输出: 1. 单词边界 \bcat\b: ['cat']
    
    # 2. 非单词边界 \B
    non_word_boundary_pattern = r"\Bcat\B"
    non_word_boundary_matches = re.findall(non_word_boundary_pattern, text)
    print(f"2. 非单词边界 \\Bcat\\B: {non_word_boundary_matches}")  # 输出: 2. 非单词边界 \Bcat\B: ['cat']
    
    # 3. 字符串开头 ^
    lines = ["first line", "second line", "third line"]
    start_pattern = r"^f"
    for line in lines:
        if re.search(start_pattern, line):
            print(f"3. 以'f'开头的行: {line}")  # 输出: 3. 以'f'开头的行: first line
    
    # 4. 字符串结尾 $
    end_pattern = r"e$"
    for line in lines:
        if re.search(end_pattern, line):
            print(f"4. 以'e'结尾的行: {line}")  # 输出: 4. 以'e'结尾的行: first line
    
    # 5. 多行模式下的 ^ 和 $
    multiline_text = "first line\nsecond line\nthird line"
    
    # 默认单行模式
    default_matches = re.findall(r"^.*$", multiline_text)
    print(f"5. 单行模式匹配: {default_matches}")  # 输出: 5. 单行模式匹配: ['first line\nsecond line\nthird line']
    
    # 多行模式
    multiline_matches = re.findall(r"^.*$", multiline_text, re.MULTILINE)
    print(f"6. 多行模式匹配: {multiline_matches}")  # 输出: 6. 多行模式匹配: ['first line', 'second line', 'third line']

anchors_and_boundaries()
```

## 5. 分组和捕获

### 5.1 基本分组
```python
def grouping_and_capturing():
    """分组和捕获：使用括号创建子模式"""
    
    text = "John: 30, Alice: 25, Bob: 35"
    
    print("分组和捕获演示:")
    
    # 1. 基本分组
    basic_pattern = r"(\w+): (\d+)"
    basic_matches = re.findall(basic_pattern, text)
    print(f"1. 基本分组匹配: {basic_matches}")
    # 输出: 1. 基本分组匹配: [('John', '30'), ('Alice', '25'), ('Bob', '35')]
    
    # 2. 使用 finditer 获取详细信息
    print("2. 使用 finditer 获取详细信息:")
    for match in re.finditer(basic_pattern, text):
        print(f"   完整匹配: '{match.group(0)}'")
        print(f"   姓名: '{match.group(1)}', 年龄: '{match.group(2)}'")
        print(f"   匹配位置: {match.start()} 到 {match.end()}")
        print(f"   所有分组: {match.groups()}")
        print()
    # 输出:
    # 完整匹配: 'John: 30'
    # 姓名: 'John', 年龄: '30'
    # 匹配位置: 0 到 8
    # 所有分组: ('John', '30')
    # ...
    
    # 3. 嵌套分组
    nested_text = "Date: 2023-12-25"
    nested_pattern = r"(\d{4})-(\d{2})-(\d{2})"
    nested_match = re.search(nested_pattern, nested_text)
    if nested_match:
        print(f"3. 嵌套分组:")
        print(f"   完整日期: {nested_match.group(0)}")  # 输出: 完整日期: 2023-12-25
        print(f"   年: {nested_match.group(1)}")        # 输出: 年: 2023
        print(f"   月: {nested_match.group(2)}")        # 输出: 月: 12
        print(f"   日: {nested_match.group(3)}")        # 输出: 日: 25
    
    # 4. 非捕获分组 (?:...)
    non_capturing_pattern = r"(?:\w+): (\d+)"
    non_capturing_matches = re.findall(non_capturing_pattern, text)
    print(f"4. 非捕获分组: {non_capturing_matches}")  # 输出: 4. 非捕获分组: ['30', '25', '35']

grouping_and_capturing()
```

### 5.2 命名分组和反向引用
```python
def named_groups_and_backreferences():
    """命名分组和反向引用"""
    
    print("命名分组和反向引用演示:")
    
    # 1. 命名分组 (?P<name>...)
    text = "John Doe, Alice Smith, Bob Johnson"
    named_pattern = r"(?P<first_name>\w+) (?P<last_name>\w+)"
    
    print("1. 命名分组:")
    for match in re.finditer(named_pattern, text):
        print(f"   全名: {match.group(0)}")
        print(f"   名: {match.group('first_name')}")
        print(f"   姓: {match.group('last_name')}")
        print(f"   分组字典: {match.groupdict()}")
        print()
    # 输出:
    # 全名: John Doe
    # 名: John
    # 姓: Doe
    # 分组字典: {'first_name': 'John', 'last_name': 'Doe'}
    
    # 2. 反向引用 \1, \2, ... 或 (?P=name)
    duplicate_text = "hello hello world world"
    
    # 使用数字反向引用
    backref_pattern1 = r"(\w+) \1"
    backref_matches1 = re.findall(backref_pattern1, duplicate_text)
    print(f"2. 数字反向引用: {backref_matches1}")  # 输出: 2. 数字反向引用: ['hello', 'world']
    
    # 使用命名反向引用
    backref_pattern2 = r"(?P<word>\w+) (?P=word)"
    backref_matches2 = re.findall(backref_pattern2, duplicate_text)
    print(f"3. 命名反向引用: {backref_matches2}")  # 输出: 3. 命名反向引用: ['hello', 'world']
    
    # 3. 在替换中使用分组
    replacement_text = "John Smith (30)"
    replacement_pattern = r"(\w+) (\w+) \((\d+)\)"
    
    # 使用 \1, \2, \3 引用分组
    result1 = re.sub(replacement_pattern, r"姓名: \1 \2, 年龄: \3", replacement_text)
    print(f"4. 替换中的分组引用: {result1}")  # 输出: 4. 替换中的分组引用: 姓名: John Smith, 年龄: 30
    
    # 使用命名分组在替换中引用
    replacement_pattern_named = r"(?P<first>\w+) (?P<last>\w+) \((?P<age>\d+)\)"
    result2 = re.sub(replacement_pattern_named, r"姓: \g<last>, 名: \g<first>, 年龄: \g<age>", replacement_text)
    print(f"5. 替换中的命名分组引用: {result2}")  # 输出: 5. 替换中的命名分组引用: 姓: Smith, 名: John, 年龄: 30

named_groups_and_backreferences()
```

## 6. 条件匹配和断言

### 6.1 前后查找断言
```python
def lookaround_assertions():
    """前后查找断言：匹配位置而不是字符"""
    
    text = "apple $100, orange $200, banana $50"
    
    print("前后查找断言演示:")
    
    # 1. 正向前查找 (?=...) - 后面是...的位置
    positive_lookahead = r"\d+(?=,)"  # 匹配后面是逗号的数字
    lookahead_matches = re.findall(positive_lookahead, text)
    print(f"1. 正向前查找 (?=,): {lookahead_matches}")  # 输出: 1. 正向前查找 (?=,): ['100', '200']
    
    # 2. 负向前查找 (?!...) - 后面不是...的位置
    negative_lookahead = r"\d+(?!,)"  # 匹配后面不是逗号的数字
    negative_lookahead_matches = re.findall(negative_lookahead, text)
    print(f"2. 负向前查找 (?!,): {negative_lookahead_matches}")  # 输出: 2. 负向前查找 (?!,): ['50']
    
    # 3. 正向后查找 (?<=...) - 前面是...的位置
    positive_lookbehind = r"(?<=\$)\d+"  # 匹配前面是$的数字
    lookbehind_matches = re.findall(positive_lookbehind, text)
    print(f"3. 正向后查找 (?<=\$): {lookbehind_matches}")  # 输出: 3. 正向后查找 (?<=\$): ['100', '200', '50']
    
    # 4. 负向后查找 (?<!...) - 前面不是...的位置
    negative_lookbehind = r"(?<!\$)\d+"  # 匹配前面不是$的数字
    negative_lookbehind_matches = re.findall(negative_lookbehind, text)
    print(f"4. 负向后查找 (?<!\$): {negative_lookbehind_matches}")  # 输出: 4. 负向后查找 (?<!\$): []
    
    # 5. 实际应用：提取引号内的内容但不包括引号
    quote_text = 'He said "hello" and she said "goodbye"'
    quote_pattern = r'(?<=")[^"]+(?=")'  # 前面是"，后面是"，但不包括引号
    quote_matches = re.findall(quote_pattern, quote_text)
    print(f"5. 提取引号内容: {quote_matches}")  # 输出: 5. 提取引号内容: ['hello', 'goodbye']

lookaround_assertions()
```

### 6.2 条件匹配
```python
def conditional_matching():
    """条件匹配：根据前面是否匹配来决定当前匹配"""
    
    print("条件匹配演示:")
    
    # 1. 基于分组是否匹配的条件 (?(id)yes|no)
    text1 = "<div>content</div>"
    text2 = "<div>content</p>"  # 不匹配的标签
    
    conditional_pattern = r"<(\w+)>.*?(?(1)</\1>|)"
    
    match1 = re.search(conditional_pattern, text1)
    match2 = re.search(conditional_pattern, text2)
    
    print(f"1. 条件匹配结果:")
    print(f"   '{text1}' → {match1.group() if match1 else '不匹配'}")  # 输出: '<div>content</div>'
    print(f"   '{text2}' → {match2.group() if match2 else '不匹配'}")  # 输出: '不匹配'
    
    # 2. 实际应用：匹配美国电话号码格式
    phone_numbers = [
        "123-456-7890",
        "(123) 456-7890", 
        "1234567890",
        "123-45-6789"
    ]
    
    phone_pattern = r"(\()?\d{3}(?(1)\)|[- ])?\d{3}[- ]?\d{4}"
    
    print("2. 电话号码匹配:")
    for phone in phone_numbers:
        match = re.search(phone_pattern, phone)
        status = "✓ 匹配" if match else "✗ 不匹配"
        print(f"   {phone:15} → {status}")

conditional_matching()
```

## 7. 标志和模式修饰符

### 7.1 常用标志
```python
def flags_and_modifiers():
    """正则表达式标志和模式修饰符"""
    
    text = "Hello\nWORLD\npython"
    
    print("标志和修饰符演示:")
    
    # 1. re.IGNORECASE (re.I) - 忽略大小写
    pattern1 = r"hello"
    match1_normal = re.search(pattern1, text)
    match1_ignore = re.search(pattern1, text, re.IGNORECASE)
    print(f"1. 忽略大小写:")
    print(f"   默认: {match1_normal.group() if match1_normal else '不匹配'}")
    print(f"   忽略大小写: {match1_ignore.group() if match1_ignore else '不匹配'}")
    # 输出: 默认: 不匹配
    # 输出: 忽略大小写: Hello
    
    # 2. re.MULTILINE (re.M) - 多行模式
    pattern2 = r"^.+$"
    matches2_single = re.findall(pattern2, text)
    matches2_multi = re.findall(pattern2, text, re.MULTILINE)
    print(f"2. 多行模式:")
    print(f"   单行模式: {matches2_single}")  # 输出: 单行模式: ['Hello\nWORLD\npython']
    print(f"   多行模式: {matches2_multi}")   # 输出: 多行模式: ['Hello', 'WORLD', 'python']
    
    # 3. re.DOTALL (re.S) - 点号匹配所有字符（包括换行符）
    pattern3 = r"Hello.*python"
    match3_normal = re.search(pattern3, text)
    match3_dotall = re.search(pattern3, text, re.DOTALL)
    print(f"3. DOTALL模式:")
    print(f"   默认: {match3_normal.group() if match3_normal else '不匹配'}")
    print(f"   DOTALL: {match3_dotall.group() if match3_dotall else '不匹配'}")
    # 输出: 默认: 不匹配
    # 输出: DOTALL: Hello\nWORLD\npython
    
    # 4. re.VERBOSE (re.X) - 详细模式（允许注释和空白）
    complex_pattern = r"""
        \b          # 单词边界
        [A-Z]       # 大写字母开头
        \w*         # 零个或多个单词字符
        \b          # 单词边界
    """
    verbose_matches = re.findall(complex_pattern, text, re.VERBOSE)
    print(f"4. 详细模式匹配: {verbose_matches}")  # 输出: 4. 详细模式匹配: ['Hello', 'WORLD']
    
    # 5. 组合使用多个标志
    combined_matches = re.findall(r"^[a-z]+$", text, re.IGNORECASE | re.MULTILINE)
    print(f"5. 组合标志（忽略大小写+多行）: {combined_matches}")  # 输出: 5. 组合标志（忽略大小写+多行）: ['Hello', 'WORLD', 'python']

flags_and_modifiers()
```

## 8. 编译正则表达式

### 8.1 预编译模式
```python
def compiled_patterns():
    """编译正则表达式：提高性能，特别是重复使用时"""
    
    import time
    
    text = "This is a test text with multiple email addresses: test1@example.com, test2@sample.org, test3@demo.net"
    
    print("编译正则表达式演示:")
    
    # 邮箱验证模式
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    
    # 1. 直接使用（每次都要编译）
    start_time = time.time()
    for i in range(1000):
        emails_direct = re.findall(email_pattern, text)
    direct_time = time.time() - start_time
    
    # 2. 使用编译后的模式
    compiled_pattern = re.compile(email_pattern)
    start_time = time.time()
    for i in range(1000):
        emails_compiled = compiled_pattern.findall(text)
    compiled_time = time.time() - start_time
    
    print(f"1. 性能比较:")
    print(f"   直接使用: {direct_time:.4f} 秒")
    print(f"   编译使用: {compiled_time:.4f} 秒")
    print(f"   性能提升: {direct_time/compiled_time:.1f} 倍")
    print(f"   找到的邮箱: {emails_compiled}")
    # 输出示例:
    # 直接使用: 0.0123 秒
    # 编译使用: 0.0034 秒  
    # 性能提升: 3.6 倍
    # 找到的邮箱: ['test1@example.com', 'test2@sample.org', 'test3@demo.net']
    
    # 3. 编译模式的方法
    print("2. 编译模式的方法:")
    methods = [
        "pattern.search(string)",
        "pattern.match(string)", 
        "pattern.findall(string)",
        "pattern.finditer(string)",
        "pattern.sub(repl, string)",
        "pattern.split(string)"
    ]
    
    for method in methods:
        print(f"   {method}")
    
    # 4. 带标志的编译
    compiled_with_flags = re.compile(r'^hello', re.IGNORECASE | re.MULTILINE)
    test_text = "Hello world\nhello python\nHELLO regex"
    matches = compiled_with_flags.findall(test_text)
    print(f"3. 带标志编译: {matches}")  # 输出: 3. 带标志编译: ['Hello', 'hello', 'HELLO']

compiled_patterns()
```

## 9. 常用正则表达式模式

### 9.1 实用模式集合
```python
def common_patterns():
    """常用正则表达式模式集合"""
    
    print("常用正则表达式模式:")
    
    # 测试数据
    test_cases = {
        "邮箱地址": [
            "test@example.com",
            "user.name+tag@domain.co.uk", 
            "invalid.email",
            "missing@domain"
        ],
        "URL": [
            "https://www.example.com",
            "http://sub.domain.co.uk/path",
            "ftp://files.server.org",
            "invalid.url"
        ],
        "电话号码": [
            "123-456-7890",
            "(123) 456-7890",
            "123.456.7890", 
            "1234567890",
            "123-45-6789"
        ],
        "IP地址": [
            "192.168.1.1",
            "10.0.0.1",
            "256.300.400.500",  # 无效
            "192.168.1"         # 无效
        ],
        "日期": [
            "2023-12-25",
            "12/25/2023", 
            "25-12-2023",
            "2023/12/25",
            "invalid-date"
        ]
    }
    
    # 对应的正则表达式模式
    patterns = {
        "邮箱地址": r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$',
        "URL": r'^(https?|ftp)://[^\s/$.?#].[^\s]*$',
        "电话号码": r'^\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})$',
        "IP地址": r'^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$',
        "日期": r'^\d{4}[-/](0[1-9]|1[0-2])[-/](0[1-9]|[12][0-9]|3[01])$'
    }
    
    for category, examples in test_cases.items():
        pattern = patterns[category]
        compiled_pattern = re.compile(pattern)
        
        print(f"\n{category}验证:")
        for example in examples:
            is_valid = bool(compiled_pattern.match(example))
            status = "✓ 有效" if is_valid else "✗ 无效"
            print(f"  {example:30} → {status}")

common_patterns()
```

## 10. 高级技巧和最佳实践

### 10.1 性能优化技巧
```python
def performance_optimization():
    """正则表达式性能优化技巧"""
    
    import time
    
    print("性能优化技巧:")
    
    # 1. 避免灾难性回溯
    print("1. 避免灾难性回溯:")
    
    # 危险模式：嵌套量词
    dangerous_pattern = r"(a+)+b"
    safe_pattern = r"a+b"
    
    test_string = "a" * 20  # 20个a
    
    # 测试危险模式（可能很慢）
    try:
        start = time.time()
        match_dangerous = re.match(dangerous_pattern, test_string + "b")
        dangerous_time = time.time() - start
        print(f"   危险模式耗时: {dangerous_time:.4f}秒")
    except:
        print("   危险模式超时或出错")
    
    # 测试安全模式
    start = time.time()
    match_safe = re.match(safe_pattern, test_string + "b")
    safe_time = time.time() - start
    print(f"   安全模式耗时: {safe_time:.4f}秒")
    
    # 2. 使用字符类而不是选择分支
    print("2. 优化选择分支:")
    
    # 不优化的方式
    slow_pattern = r"apple|banana|orange|grape|peach"
    # 优化的方式（如果可能）
    fast_pattern = r"[abogp][a-z]*"  # 简化示例
    
    fruits = "apple banana orange grape peach"
    
    start = time.time()
    for i in range(1000):
        re.findall(slow_pattern, fruits)
    slow_time = time.time() - start
    
    start = time.time()
    for i in range(1000):
        re.findall(fast_pattern, fruits)
    fast_time = time.time() - start
    
    print(f"   选择分支耗时: {slow_time:.4f}秒")
    print(f"   字符类耗时: {fast_time:.4f}秒")
    
    # 3. 使用锚点提高速度
    print("3. 使用锚点优化:")
    
    text = "This is a long text that contains the word example multiple times."
    
    # 没有锚点
    start = time.time()
    for i in range(1000):
        re.search(r"example", text)
    no_anchor_time = time.time() - start
    
    # 有锚点（如果知道位置）
    start = time.time()
    for i in range(1000):
        re.search(r"^.*example", text)
    anchor_time = time.time() - start
    
    print(f"   无锚点耗时: {no_anchor_time:.4f}秒")
    print(f"   有锚点耗时: {anchor_time:.4f}秒")

performance_optimization()
```

### 10.2 调试和测试技巧
```python
def debugging_and_testing():
    """正则表达式调试和测试技巧"""
    
    print("调试和测试技巧:")
    
    # 1. 使用 re.DEBUG 标志
    print("1. 使用 DEBUG 标志:")
    try:
        pattern = re.compile(r'\d{3}-\d{2}-\d{4}', re.DEBUG)
        # 输出编译过程的详细信息
    except:
        print("   DEBUG 输出较长，这里不显示")
    
    # 2. 逐步构建复杂模式
    print("2. 逐步构建模式:")
    
    # 构建邮箱验证模式
    steps = [
        r"\w+",                      # 用户名部分
        r"\w+@",                     # 加上@
        r"\w+@\w+",                  # 加上域名
        r"\w+@\w+\.\w+",             # 加上顶级域名
        r"\b\w+@\w+\.\w+\b",         # 加上单词边界
        r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b"  # 完整模式
    ]
    
    test_emails = ["test@example.com", "user@domain", "invalid.email"]
    
    for i, step_pattern in enumerate(steps, 1):
        print(f"   步骤 {i}: {step_pattern}")
        pattern = re.compile(step_pattern)
        for email in test_emails:
            match = pattern.search(email)
            if match:
                print(f"     {email} → 匹配: {match.group()}")
            else:
                print(f"     {email} → 不匹配")
        print()
    
    # 3. 使用在线测试工具
    print("3. 推荐在线测试工具:")
    tools = [
        "regex101.com - 功能强大的正则表达式测试器",
        "regexr.com - 交互式学习和测试工具", 
        "debuggex.com - 可视化正则表达式",
        "pythex.org - 专门针对Python正则表达式"
    ]
    
    for tool in tools:
        print(f"   • {tool}")
    
    # 4. 单元测试正则表达式
    print("4. 单元测试示例:")
    
    def test_regex_pattern():
        """测试邮箱验证模式"""
        pattern = r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$'
        compiled = re.compile(pattern)
        
        test_cases = {
            "test@example.com": True,
            "user.name+tag@domain.co.uk": True,
            "invalid.email": False,
            "missing@domain": False,
            "": False
        }
        
        all_passed = True
        for test_input, expected in test_cases.items():
            result = bool(compiled.match(test_input))
            status = "✓" if result == expected else "✗"
            print(f"     {status} {test_input:30} → 期望: {expected}, 实际: {result}")
            if result != expected:
                all_passed = False
        
        return all_passed
    
    test_regex_pattern()

debugging_and_testing()
```

## 11. 实际应用案例

### 11.1 日志文件分析
```python
def log_analysis_example():
    """使用正则表达式分析日志文件"""
    
    # 模拟日志数据
    log_data = """
    2023-12-01 10:30:15 INFO User john.doe logged in from 192.168.1.100
    2023-12-01 10:35:22 ERROR Database connection failed - timeout after 30s
    2023-12-01 10:40:10 WARNING High memory usage detected: 85%
    2023-12-01 10:45:05 INFO User alice.smith accessed /api/users
    2023-12-01 10:50:33 ERROR Payment processing failed for order #12345
    2023-12-01 10:55:47 INFO User bob.johnson logged out
    """
    
    print("日志文件分析:")
    
    # 1. 提取所有错误日志
    error_pattern = r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2} ERROR (.+)'
    errors = re.findall(error_pattern, log_data)
    print("1. 错误日志:")
    for error in errors:
        print(f"   • {error}")
    # 输出:
    # • Database connection failed - timeout after 30s
    # • Payment processing failed for order #12345
    
    # 2. 提取IP地址
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    ips = re.findall(ip_pattern, log_data)
    print(f"2. IP地址: {ips}")  # 输出: IP地址: ['192.168.1.100']
    
    # 3. 提取用户名
    user_pattern = r'User (\w+\.\w+)'
    users = re.findall(user_pattern, log_data)
    print(f"3. 用户列表: {users}")  # 输出: 用户列表: ['john.doe', 'alice.smith', 'bob.johnson']
    
    # 4. 提取时间戳和日志级别
    log_entry_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) (.*)'
    log_entries = re.findall(log_entry_pattern, log_data)
    
    print("4. 日志统计:")
    level_count = {}
    for timestamp, level, message in log_entries:
        level_count[level] = level_count.get(level, 0) + 1
    
    for level, count in level_count.items():
        print(f"   {level}: {count} 条")

log_analysis_example()
```

### 11.2 数据清洗和提取
```python
def data_cleaning_example():
    """使用正则表达式进行数据清洗和提取"""
    
    # 模拟杂乱的数据
    messy_data = """
    姓名: 张三, 电话: 138-1234-5678, 邮箱: zhangsan@example.com
    姓名：李四，电话：13987654321，邮箱：lisi@test.com
    Name: John Doe, Phone: (123) 456-7890, Email: john.doe@sample.org
    姓名: 王五, 电话: 137 5555 6666, 邮箱: wangwu@demo.net
    """
    
    print("数据清洗和提取:")
    
    # 1. 统一提取姓名
    name_pattern = r'(?:姓名[:：]|Name:)\s*([^\s,，]+(?:\s+[^\s,，]+)*)'
    names = re.findall(name_pattern, messy_data)
    print(f"1. 提取的姓名: {names}")
    # 输出: 提取的姓名: ['张三', '李四', 'John Doe', '王五']
    
    # 2. 统一提取电话号码
    phone_pattern = r'(?:电话[:：]|Phone:)\s*([\(\d\)\-\s]+)'
    raw_phones = re.findall(phone_pattern, messy_data)
    
    # 清理电话号码格式
    cleaned_phones = []
    for phone in raw_phones:
        # 移除非数字字符
        cleaned = re.sub(r'[^\d]', '', phone)
        cleaned_phones.append(cleaned)
    
    print(f"2. 清理后的电话: {cleaned_phones}")
    # 输出: 清理后的电话: ['13812345678', '13987654321', '1234567890', '13755556666']
    
    # 3. 提取邮箱地址
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    emails = re.findall(email_pattern, messy_data)
    print(f"3. 邮箱地址: {emails}")
    # 输出: 邮箱地址: ['zhangsan@example.com', 'lisi@test.com', 'john.doe@sample.org', 'wangwu@demo.net']
    
    # 4. 结构化数据
    structured_pattern = r'(?:姓名[:：]|Name:)\s*([^,，]+).*?(?:电话[:：]|Phone:)\s*([^,，]+).*?(?:邮箱[:：]|Email:)?\s*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'
    
    structured_data = []
    for match in re.finditer(structured_pattern, messy_data, re.DOTALL):
        name, phone, email = match.groups()
        # 清理电话号码
        clean_phone = re.sub(r'[^\d]', '', phone)
        structured_data.append({
            'name': name.strip(),
            'phone': clean_phone,
            'email': email
        })
    
    print("4. 结构化数据:")
    for person in structured_data:
        print(f"   姓名: {person['name']}, 电话: {person['phone']}, 邮箱: {person['email']}")

data_cleaning_example()
```

这份超详细的Python正则表达式笔记涵盖了从基础到高级的所有重要知识点，包括：

1. **基础概念** - 正则表达式介绍、re模块
2. **基本匹配** - 字面量、字符类、预定义字符类
3. **量词和重复** - 各种量词、贪婪vs非贪婪匹配
4. **位置匹配** - 边界、锚点、单词边界
5. **分组捕获** - 基本分组、命名分组、反向引用
6. **条件断言** - 前后查找断言、条件匹配
7. **标志修饰符** - 各种标志的使用和组合
8. **性能优化** - 编译模式、避免灾难性回溯
9. **调试测试** - 调试技巧、单元测试
10. **实际应用** - 日志分析、数据清洗

每个部分都包含了详细的代码注释、易错点说明和使用技巧，确保初学者能够全面理解和掌握Python正则表达式的使用。