# Python线程编程超详细笔记

## 1. 线程基础概念

### 1.1 什么是线程
```python
"""
线程：操作系统能够进行运算调度的最小单位，被包含在进程之中，是进程中的实际运作单位
一个进程可以包含多个线程，所有线程共享进程的内存和资源
"""

import threading
import time
import os

def basic_worker(thread_name, duration):
    """基本的线程工作函数"""
    print(f"线程 {thread_name} 开始执行")
    print(f"线程 {thread_name} 的ID: {threading.get_ident()}")
    print(f"线程 {thread_name} 所属进程ID: {os.getpid()}")
    
    # 模拟工作
    time.sleep(duration)
    
    print(f"线程 {thread_name} 完成执行")

# 创建和启动线程
if __name__ == "__main__":
    print("=== 线程基础概念演示 ===")
    print(f"主线程ID: {threading.get_ident()}")
    print(f"主线程名称: {threading.current_thread().name}")
    print(f"进程ID: {os.getpid()}")
    
    # 创建线程
    thread1 = threading.Thread(target=basic_worker, args=("工作线程1", 2))
    thread2 = threading.Thread(target=basic_worker, args=("工作线程2", 1))
    
    # 启动线程
    thread1.start()
    thread2.start()
    
    print("主线程继续执行其他工作...")
    
    # 等待线程完成
    thread1.join()
    thread2.join()
    
    print("所有线程执行完毕")

# 输出示例：
# === 线程基础概念演示 ===
# 主线程ID: 140736
# 主线程名称: MainThread
# 进程ID: 1234
# 主线程继续执行其他工作...
# 线程 工作线程1 开始执行
# 线程 工作线程1 的ID: 123456
# 线程 工作线程1 所属进程ID: 1234
# 线程 工作线程2 开始执行
# 线程 工作线程2 的ID: 123457
# 线程 工作线程2 所属进程ID: 1234
# 线程 工作线程2 完成执行
# 线程 工作线程1 完成执行
# 所有线程执行完毕
```

### 1.2 线程与进程的区别
```python
import threading
import multiprocessing
import time

shared_list = []  # 全局变量

def thread_worker(name):
    """线程工作函数 - 共享内存"""
    shared_list.append(f"线程{name}")
    print(f"线程 {name}: 列表内容: {shared_list}")

def process_worker(name):
    """进程工作函数 - 内存隔离"""
    # 注意：进程中的修改不会影响主进程
    shared_list.append(f"进程{name}")
    print(f"进程 {name}: 列表内容: {shared_list}")

if __name__ == "__main__":
    print("=== 线程 vs 进程内存模型 ===")
    
    # 线程测试
    print("\n--- 线程共享内存 ---")
    thread_workers = []
    for i in range(3):
        t = threading.Thread(target=thread_worker, args=(i,))
        thread_workers.append(t)
        t.start()
    
    for t in thread_workers:
        t.join()
    
    print(f"主线程中的列表: {shared_list}")
    
    # 进程测试
    print("\n--- 进程内存隔离 ---")
    shared_list.clear()  # 清空列表
    
    process_workers = []
    for i in range(3):
        p = multiprocessing.Process(target=process_worker, args=(i,))
        process_workers.append(p)
        p.start()
    
    for p in process_workers:
        p.join()
    
    print(f"主进程中的列表: {shared_list}")

# 输出示例：
# === 线程 vs 进程内存模型 ===
#
# --- 线程共享内存 ---
# 线程 0: 列表内容: ['线程0']
# 线程 1: 列表内容: ['线程0', '线程1']
# 线程 2: 列表内容: ['线程0', '线程1', '线程2']
# 主线程中的列表: ['线程0', '线程1', '线程2']
#
# --- 进程内存隔离 ---
# 进程 0: 列表内容: ['进程0']
# 进程 1: 列表内容: ['进程1']
# 进程 2: 列表内容: ['进程2']
# 主进程中的列表: []
```

## 2. 创建和管理线程

### 2.1 创建线程的多种方式
```python
import threading
import time

# 方式1：使用函数创建线程
def function_worker(name, count):
    """函数式线程"""
    for i in range(count):
        print(f"函数线程 {name}: 计数 {i}")
        time.sleep(0.1)

# 方式2：继承Thread类
class CustomThread(threading.Thread):
    """自定义线程类"""
    
    def __init__(self, name, count):
        super().__init__()
        self.name = name
        self.count = count
        self.result = None
    
    def run(self):
        """重写run方法，线程入口点"""
        print(f"自定义线程 {self.name} 开始执行")
        total = 0
        for i in range(self.count):
            total += i
            print(f"自定义线程 {self.name}: 累加 {total}")
            time.sleep(0.1)
        self.result = total
        print(f"自定义线程 {self.name} 完成，结果: {total}")

# 方式3：使用lambda表达式
def create_threads():
    """演示多种创建线程的方式"""
    print("=== 创建线程的多种方式 ===")
    
    # 方式1：函数线程
    print("\n--- 函数线程 ---")
    func_thread = threading.Thread(
        target=function_worker, 
        args=("FuncThread", 3),
        name="FunctionWorkerThread"
    )
    
    # 方式2：自定义线程类
    print("\n--- 自定义线程类 ---")
    custom_thread = CustomThread("CustomThread", 4)
    
    # 方式3：lambda表达式线程
    print("\n--- Lambda线程 ---")
    lambda_thread = threading.Thread(
        target=lambda: print("Lambda线程执行"),
        name="LambdaThread"
    )
    
    # 启动所有线程
    threads = [func_thread, custom_thread, lambda_thread]
    for t in threads:
        t.start()
    
    # 等待线程完成
    for t in threads:
        t.join()
    
    # 获取自定义线程的结果
    print(f"\n自定义线程的结果: {custom_thread.result}")

if __name__ == "__main__":
    create_threads()

# 输出示例：
# === 创建线程的多种方式 ===
#
# --- 函数线程 ---
# --- 自定义线程类 ---
# --- Lambda线程 ---
# 函数线程 FuncThread: 计数 0
# 自定义线程 CustomThread 开始执行
# 自定义线程 CustomThread: 累加 0
# Lambda线程执行
# 函数线程 FuncThread: 计数 1
# 自定义线程 CustomThread: 累加 1
# ...（后续输出）
# 自定义线程 CustomThread 完成，结果: 6
#
# 自定义线程的结果: 6
```

### 2.2 线程的生命周期管理
```python
import threading
import time
import random

def lifecycle_worker(thread_id):
    """演示线程生命周期的worker函数"""
    print(f"线程 {thread_id} 开始运行")
    
    # 模拟工作
    for i in range(5):
        if threading.current_thread().is_alive():
            print(f"线程 {thread_id} 执行第 {i+1} 步")
            time.sleep(random.uniform(0.1, 0.3))
        else:
            print(f"线程 {thread_id} 被中断")
            break
    
    print(f"线程 {thread_id} 正常结束")

def monitor_threads(threads):
    """监控线程状态"""
    print("\n=== 线程状态监控 ===")
    for i, t in enumerate(threads):
        status = "活跃" if t.is_alive() else "结束"
        print(f"线程 {i}: {status} (名称: {t.name})")

if __name__ == "__main__":
    print("=== 线程生命周期管理 ===")
    
    # 创建线程
    threads = []
    for i in range(3):
        t = threading.Thread(
            target=lifecycle_worker,
            args=(i,),
            name=f"WorkerThread-{i}"
        )
        threads.append(t)
    
    # 启动线程
    for t in threads:
        t.start()
        time.sleep(0.1)  # 错开启动时间
    
    # 监控线程状态
    for _ in range(3):
        monitor_threads(threads)
        time.sleep(0.5)
    
    # 等待所有线程完成
    for t in threads:
        t.join()
    
    monitor_threads(threads)
    print("所有线程执行完毕")

# 输出示例：
# === 线程生命周期管理 ===
# 线程 0 开始运行
# 线程 0 执行第 1 步
# 线程 1 开始运行
# 线程 1 执行第 1 步
# 线程 2 开始运行
# 线程 2 执行第 1 步
#
# === 线程状态监控 ===
# 线程 0: 活跃 (名称: WorkerThread-0)
# 线程 1: 活跃 (名称: WorkerThread-1)
# 线程 2: 活跃 (名称: WorkerThread-2)
#
# === 线程状态监控 ===
# 线程 0: 活跃 (名称: WorkerThread-0)
# 线程 1: 活跃 (名称: WorkerThread-1)
# 线程 2: 活跃 (名称: WorkerThread-2)
# 线程 0 正常结束
# 线程 1 正常结束
# 线程 2 正常结束
#
# === 线程状态监控 ===
# 线程 0: 结束 (名称: WorkerThread-0)
# 线程 1: 结束 (名称: WorkerThread-1)
# 线程 2: 结束 (名称: WorkerThread-2)
# 所有线程执行完毕
```

## 3. 线程同步

### 3.1 使用Lock防止竞态条件
```python
import threading
import time

class BankAccount:
    """银行账户类，演示竞态条件"""
    
    def __init__(self, initial_balance=0):
        self.balance = initial_balance
        self.lock = threading.Lock()  # 创建锁
    
    def deposit(self, amount):
        """存款 - 无锁版本（有问题）"""
        # 模拟一些处理时间
        time.sleep(0.001)
        new_balance = self.balance + amount
        # 模拟一些处理时间
        time.sleep(0.001)
        self.balance = new_balance
    
    def safe_deposit(self, amount):
        """存款 - 有锁版本（正确）"""
        with self.lock:  # 自动获取和释放锁
            # 模拟一些处理时间
            time.sleep(0.001)
            new_balance = self.balance + amount
            # 模拟一些处理时间
            time.sleep(0.001)
            self.balance = new_balance
    
    def get_balance(self):
        """获取余额"""
        return self.balance

def unsafe_worker(account, amount, count):
    """不安全的worker函数"""
    for _ in range(count):
        account.deposit(amount)

def safe_worker(account, amount, count):
    """安全的worker函数"""
    for _ in range(count):
        account.safe_deposit(amount)

def test_race_condition():
    """测试竞态条件"""
    print("=== 竞态条件测试 ===")
    
    # 测试不安全版本
    print("\n--- 不安全版本 ---")
    unsafe_account = BankAccount(1000)
    threads = []
    
    # 创建多个线程同时存款
    for _ in range(10):
        t = threading.Thread(target=unsafe_worker, args=(unsafe_account, 1, 100))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"预期余额: {1000 + 10 * 100 * 1}")  # 1000 + 10*100*1 = 2000
    print(f"实际余额: {unsafe_account.get_balance()}")
    
    # 测试安全版本
    print("\n--- 安全版本（使用锁） ---")
    safe_account = BankAccount(1000)
    threads = []
    
    # 创建多个线程同时存款
    for _ in range(10):
        t = threading.Thread(target=safe_worker, args=(safe_account, 1, 100))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"预期余额: {1000 + 10 * 100 * 1}")  # 1000 + 10*100*1 = 2000
    print(f"实际余额: {safe_account.get_balance()}")

if __name__ == "__main__":
    test_race_condition()

# 输出示例：
# === 竞态条件测试 ===
#
# --- 不安全版本 ---
# 预期余额: 2000
# 实际余额: 1563  # 由于竞态条件，结果不正确
#
# --- 安全版本（使用锁） ---
# 预期余额: 2000
# 实际余额: 2000  # 使用锁后结果正确
```

### 3.2 使用RLock（可重入锁）
```python
import threading
import time

class RecursiveCounter:
    """演示可重入锁的使用"""
    
    def __init__(self):
        self._value = 0
        self._lock = threading.RLock()  # 可重入锁
    
    def increment(self):
        """增加计数器"""
        with self._lock:
            self._value += 1
            print(f"计数器增加到: {self._value}")
    
    def double_increment(self):
        """双重增加 - 会调用increment方法"""
        with self._lock:  # 同一个线程可以再次获取锁
            print("执行双重增加")
            self.increment()  # 这里会再次获取同一个锁
            self.increment()
    
    def get_value(self):
        """获取计数器值"""
        return self._value

def rlock_worker(counter, worker_id):
    """使用可重入锁的worker"""
    print(f"工作线程 {worker_id} 开始")
    
    # 调用双重增加方法
    counter.double_increment()
    
    print(f"工作线程 {worker_id} 完成")

if __name__ == "__main__":
    print("=== 可重入锁(RLock)演示 ===")
    
    counter = RecursiveCounter()
    threads = []
    
    # 创建多个工作线程
    for i in range(3):
        t = threading.Thread(target=rlock_worker, args=(counter, i))
        threads.append(t)
        t.start()
    
    # 等待所有线程完成
    for t in threads:
        t.join()
    
    print(f"最终计数器值: {counter.get_value()}")

# 输出示例：
# === 可重入锁(RLock)演示 ===
# 工作线程 0 开始
# 执行双重增加
# 计数器增加到: 1
# 计数器增加到: 2
# 工作线程 0 完成
# 工作线程 1 开始
# 执行双重增加
# 计数器增加到: 3
# 计数器增加到: 4
# 工作线程 1 完成
# 工作线程 2 开始
# 执行双重增加
# 计数器增加到: 5
# 计数器增加到: 6
# 工作线程 2 完成
# 最终计数器值: 6
```

### 3.3 使用Semaphore控制并发数量
```python
import threading
import time
import random

class ConnectionPool:
    """连接池，使用信号量控制并发连接数"""
    
    def __init__(self, total_connections):
        self.total_connections = total_connections
        self.semaphore = threading.Semaphore(total_connections)
        self.active_connections = 0
        self.lock = threading.Lock()
    
    def get_connection(self, client_id):
        """获取连接"""
        print(f"客户端 {client_id} 等待连接...")
        
        # 获取信号量（控制最大并发数）
        self.semaphore.acquire()
        
        with self.lock:
            self.active_connections += 1
        
        print(f"客户端 {client_id} 获得连接，活跃连接数: {self.active_connections}/{self.total_connections}")
        
        # 模拟使用连接
        time.sleep(random.uniform(1, 3))
        
        # 释放连接
        self.release_connection(client_id)
    
    def release_connection(self, client_id):
        """释放连接"""
        with self.lock:
            self.active_connections -= 1
        
        # 释放信号量
        self.semaphore.release()
        
        print(f"客户端 {client_id} 释放连接，活跃连接数: {self.active_connections}/{self.total_connections}")

def semaphore_demo():
    """信号量演示"""
    print("=== 信号量控制并发数量 ===")
    
    # 创建连接池，最多3个并发连接
    pool = ConnectionPool(3)
    
    # 创建多个客户端线程
    threads = []
    for i in range(8):
        t = threading.Thread(
            target=pool.get_connection,
            args=(i,),
            name=f"Client-{i}"
        )
        threads.append(t)
        t.start()
        time.sleep(0.2)  # 错开启动时间
    
    # 等待所有客户端完成
    for t in threads:
        t.join()
    
    print("所有客户端完成")

if __name__ == "__main__":
    semaphore_demo()

# 输出示例：
# === 信号量控制并发数量 ===
# 客户端 0 等待连接...
# 客户端 0 获得连接，活跃连接数: 1/3
# 客户端 1 等待连接...
# 客户端 1 获得连接，活跃连接数: 2/3
# 客户端 2 等待连接...
# 客户端 2 获得连接，活跃连接数: 3/3
# 客户端 3 等待连接...（阻塞）
# 客户端 4 等待连接...（阻塞）
# 客户端 0 释放连接，活跃连接数: 2/3
# 客户端 3 获得连接，活跃连接数: 3/3
# ...（后续输出）
# 所有客户端完成
```

### 3.4 使用Event进行线程协调
```python
import threading
import time
import random

def waiter(event, waiter_id):
    """等待事件的线程"""
    print(f"等待者 {waiter_id} 等待事件发生...")
    
    # 等待事件被设置
    event.wait()
    
    print(f"等待者 {waiter_id} 检测到事件，开始工作")
    time.sleep(1)
    print(f"等待者 {waiter_id} 完成工作")

def setter(event, setter_id):
    """设置事件的线程"""
    print(f"设置者 {setter_id} 正在准备工作...")
    
    # 模拟准备工作
    preparation_time = random.uniform(2, 4)
    time.sleep(preparation_time)
    
    # 设置事件，通知所有等待者
    print(f"设置者 {setter_id} 设置事件！")
    event.set()
    
    print(f"设置者 {setter_id} 完成")

def event_demo():
    """事件协调演示"""
    print("=== 事件(Event)线程协调 ===")
    
    # 创建事件
    event = threading.Event()
    
    # 创建等待者线程
    waiters = []
    for i in range(3):
        t = threading.Thread(target=waiter, args=(event, i))
        waiters.append(t)
        t.start()
    
    # 创建设置者线程
    setter_thread = threading.Thread(target=setter, args=(event, "MainSetter"))
    setter_thread.start()
    
    # 等待所有线程完成
    for t in waiters:
        t.join()
    setter_thread.join()
    
    print("所有线程完成")

if __name__ == "__main__":
    event_demo()

# 输出示例：
# === 事件(Event)线程协调 ===
# 等待者 0 等待事件发生...
# 等待者 1 等待事件发生...
# 等待者 2 等待事件发生...
# 设置者 MainSetter 正在准备工作...
# 设置者 MainSetter 设置事件！
# 设置者 MainSetter 完成
# 等待者 0 检测到事件，开始工作
# 等待者 1 检测到事件，开始工作
# 等待者 2 检测到事件，开始工作
# 等待者 1 完成工作
# 等待者 0 完成工作
# 等待者 2 完成工作
# 所有线程完成
```

### 3.5 使用Condition进行复杂同步
```python
import threading
import time
import random

class MessageQueue:
    """消息队列，使用Condition实现生产者-消费者模式"""
    
    def __init__(self, max_size=5):
        self.max_size = max_size
        self.messages = []
        self.condition = threading.Condition()
    
    def produce(self, message, producer_id):
        """生产消息"""
        with self.condition:
            # 等待队列有空位
            while len(self.messages) >= self.max_size:
                print(f"生产者 {producer_id} 等待，队列已满")
                self.condition.wait()
            
            # 生产消息
            self.messages.append(message)
            print(f"生产者 {producer_id} 生产: {message}, 队列大小: {len(self.messages)}")
            
            # 通知消费者
            self.condition.notify_all()
    
    def consume(self, consumer_id):
        """消费消息"""
        with self.condition:
            # 等待队列有消息
            while len(self.messages) == 0:
                print(f"消费者 {consumer_id} 等待，队列为空")
                self.condition.wait()
            
            # 消费消息
            message = self.messages.pop(0)
            print(f"消费者 {consumer_id} 消费: {message}, 队列大小: {len(self.messages)}")
            
            # 通知生产者
            self.condition.notify_all()
            
            return message

def producer_worker(queue, producer_id, count):
    """生产者工作线程"""
    for i in range(count):
        message = f"消息_{producer_id}_{i}"
        queue.produce(message, producer_id)
        time.sleep(random.uniform(0.1, 0.5))

def consumer_worker(queue, consumer_id, count):
    """消费者工作线程"""
    for i in range(count):
        message = queue.consume(consumer_id)
        time.sleep(random.uniform(0.2, 0.8))

def condition_demo():
    """Condition演示"""
    print("=== Condition生产者-消费者模式 ===")
    
    # 创建消息队列
    queue = MessageQueue(max_size=3)
    
    # 创建生产者线程
    producers = []
    for i in range(2):
        t = threading.Thread(
            target=producer_worker,
            args=(queue, f"P{i}", 5)
        )
        producers.append(t)
        t.start()
    
    # 创建消费者线程
    consumers = []
    for i in range(3):
        t = threading.Thread(
            target=consumer_worker,
            args=(queue, f"C{i}", 4)
        )
        consumers.append(t)
        t.start()
    
    # 等待所有线程完成
    for t in producers + consumers:
        t.join()
    
    print("所有线程完成")

if __name__ == "__main__":
    condition_demo()

# 输出示例：
# === Condition生产者-消费者模式 ===
# 生产者 P0 生产: 消息_P0_0, 队列大小: 1
# 生产者 P1 生产: 消息_P1_0, 队列大小: 2
# 消费者 C0 消费: 消息_P0_0, 队列大小: 1
# 消费者 C1 消费: 消息_P1_0, 队列大小: 0
# 生产者 P0 生产: 消息_P0_1, 队列大小: 1
# ...（后续输出）
# 所有线程完成
```

## 4. 线程间通信

### 4.1 使用Queue进行线程安全通信
```python
import threading
import queue
import time
import random

def producer(q, producer_id, item_count):
    """生产者线程"""
    for i in range(item_count):
        item = f"产品_{producer_id}_{i}"
        
        # 生产项目
        production_time = random.uniform(0.1, 0.5)
        time.sleep(production_time)
        
        # 放入队列
        q.put(item)
        print(f"生产者 {producer_id} 生产: {item} (队列大小: {q.qsize()})")
    
    # 发送结束信号
    q.put(None)
    print(f"生产者 {producer_id} 完成")

def consumer(q, consumer_id):
    """消费者线程"""
    while True:
        try:
            # 从队列获取项目（超时3秒）
            item = q.get(timeout=3)
            
            if item is None:
                # 结束信号，放回队列供其他消费者使用
                q.put(None)
                break
            
            # 消费项目
            consumption_time = random.uniform(0.2, 0.8)
            time.sleep(consumption_time)
            
            print(f"消费者 {consumer_id} 消费: {item} (队列大小: {q.qsize()})")
            
            # 标记任务完成
            q.task_done()
            
        except queue.Empty:
            print(f"消费者 {consumer_id} 等待超时，退出")
            break
    
    print(f"消费者 {consumer_id} 完成")

def queue_demo():
    """队列通信演示"""
    print("=== Queue线程安全通信 ===")
    
    # 创建线程安全队列，最大容量为5
    q = queue.Queue(maxsize=5)
    
    # 创建生产者线程
    producers = []
    for i in range(2):
        t = threading.Thread(
            target=producer,
            args=(q, f"P{i}", 4)
        )
        producers.append(t)
        t.start()
    
    # 创建消费者线程
    consumers = []
    for i in range(3):
        t = threading.Thread(
            target=consumer,
            args=(q, f"C{i}")
        )
        consumers.append(t)
        t.start()
    
    # 等待生产者完成
    for t in producers:
        t.join()
    
    # 等待队列中的所有任务被处理
    q.join()
    
    print("所有任务处理完成")

if __name__ == "__main__":
    queue_demo()

# 输出示例：
# === Queue线程安全通信 ===
# 生产者 P0 生产: 产品_P0_0 (队列大小: 1)
# 消费者 C0 消费: 产品_P0_0 (队列大小: 0)
# 生产者 P1 生产: 产品_P1_0 (队列大小: 1)
# 消费者 C1 消费: 产品_P1_0 (队列大小: 0)
# ...（后续输出）
# 所有任务处理完成
```

## 5. 线程局部数据

### 5.1 使用threading.local()
```python
import threading
import time
import random

# 创建线程局部数据存储
thread_local = threading.local()

def show_thread_data(worker_id):
    """显示线程局部数据"""
    # 每个线程有自己的数据
    if not hasattr(thread_local, 'data'):
        thread_local.data = []
    
    # 添加数据
    thread_local.data.append(f"数据_{worker_id}")
    
    # 模拟一些工作
    time.sleep(random.uniform(0.1, 0.3))
    
    # 显示当前线程的数据
    print(f"线程 {worker_id} (ID: {threading.get_ident()}) 的数据: {thread_local.data}")

def thread_local_demo():
    """线程局部数据演示"""
    print("=== 线程局部数据(threading.local) ===")
    
    # 创建多个线程
    threads = []
    for i in range(4):
        t = threading.Thread(target=show_thread_data, args=(i,))
        threads.append(t)
        t.start()
        time.sleep(0.1)  # 错开启动时间
    
    # 等待所有线程完成
    for t in threads:
        t.join()
    
    print("所有线程完成")

if __name__ == "__main__":
    thread_local_demo()

# 输出示例：
# === 线程局部数据(threading.local) ===
# 线程 0 (ID: 123456) 的数据: ['数据_0']
# 线程 1 (ID: 123457) 的数据: ['数据_1']
# 线程 2 (ID: 123458) 的数据: ['数据_2']
# 线程 3 (ID: 123459) 的数据: ['数据_3']
# 所有线程完成
```

### 5.2 线程局部数据的实际应用
```python
import threading
import time

class DatabaseConnectionManager:
    """数据库连接管理器，使用线程局部数据"""
    
    def __init__(self):
        self.thread_local = threading.local()
    
    def get_connection(self):
        """获取当前线程的数据库连接"""
        if not hasattr(self.thread_local, 'connection'):
            # 模拟创建数据库连接
            connection_id = f"Conn_{threading.get_ident()}"
            print(f"创建新的数据库连接: {connection_id}")
            self.thread_local.connection = {
                'id': connection_id,
                'created_at': time.time()
            }
        
        return self.thread_local.connection
    
    def close_connection(self):
        """关闭当前线程的数据库连接"""
        if hasattr(self.thread_local, 'connection'):
            connection = self.thread_local.connection
            print(f"关闭数据库连接: {connection['id']}")
            del self.thread_local.connection

def database_worker(manager, worker_id, operation_count):
    """数据库工作线程"""
    print(f"工作线程 {worker_id} 开始")
    
    for i in range(operation_count):
        # 获取连接（每个线程有自己的连接）
        connection = manager.get_connection()
        
        # 模拟数据库操作
        print(f"工作线程 {worker_id} 使用连接 {connection['id']} 执行操作 {i}")
        time.sleep(0.2)
    
    # 关闭连接
    manager.close_connection()
    
    print(f"工作线程 {worker_id} 完成")

def thread_local_practical_demo():
    """线程局部数据实际应用演示"""
    print("=== 线程局部数据实际应用 ===")
    
    # 创建连接管理器
    manager = DatabaseConnectionManager()
    
    # 创建工作线程
    threads = []
    for i in range(3):
        t = threading.Thread(
            target=database_worker,
            args=(manager, i, 3)
        )
        threads.append(t)
        t.start()
    
    # 等待所有线程完成
    for t in threads:
        t.join()
    
    print("所有数据库操作完成")

if __name__ == "__main__":
    thread_local_practical_demo()

# 输出示例：
# === 线程局部数据实际应用 ===
# 工作线程 0 开始
# 创建新的数据库连接: Conn_123456
# 工作线程 0 使用连接 Conn_123456 执行操作 0
# 工作线程 1 开始
# 创建新的数据库连接: Conn_123457
# 工作线程 1 使用连接 Conn_123457 执行操作 0
# 工作线程 2 开始
# 创建新的数据库连接: Conn_123458
# 工作线程 2 使用连接 Conn_123458 执行操作 0
# ...（后续输出）
# 所有数据库操作完成
```

## 6. 线程池

### 6.1 使用ThreadPoolExecutor
```python
import concurrent.futures
import threading
import time
import random

def cpu_intensive_task(n, task_id):
    """CPU密集型任务"""
    thread_id = threading.get_ident()
    print(f"任务 {task_id} 在线程 {thread_id} 开始执行")
    
    # 模拟CPU密集型计算
    result = sum(i * i for i in range(n))
    
    # 模拟一些处理时间
    time.sleep(random.uniform(0.5, 1.5))
    
    print(f"任务 {task_id} 完成，结果: {result}")
    return (task_id, result)

def io_intensive_task(duration, task_id):
    """I/O密集型任务"""
    thread_id = threading.get_ident()
    print(f"IO任务 {task_id} 在线程 {thread_id} 开始执行")
    
    # 模拟I/O操作
    time.sleep(duration)
    
    result = f"IO结果_{task_id}"
    print(f"IO任务 {task_id} 完成")
    return (task_id, result)

def thread_pool_demo():
    """线程池演示"""
    print("=== ThreadPoolExecutor 线程池 ===")
    
    # 创建线程池
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        print(f"线程池最大工作线程数: 3")
        
        # 提交CPU密集型任务
        print("\n--- 提交CPU密集型任务 ---")
        cpu_futures = [
            executor.submit(cpu_intensive_task, 1000000, i)
            for i in range(6)
        ]
        
        # 提交I/O密集型任务
        print("\n--- 提交I/O密集型任务 ---")
        io_futures = [
            executor.submit(io_intensive_task, random.uniform(1, 2), i)
            for i in range(4)
        ]
        
        # 收集结果
        print("\n--- 收集CPU任务结果 ---")
        for future in concurrent.futures.as_completed(cpu_futures):
            try:
                task_id, result = future.result()
                print(f"收到CPU任务 {task_id} 的结果: {result}")
            except Exception as e:
                print(f"任务执行出错: {e}")
        
        print("\n--- 收集I/O任务结果 ---")
        for future in concurrent.futures.as_completed(io_futures):
            try:
                task_id, result = future.result()
                print(f"收到IO任务 {task_id} 的结果: {result}")
            except Exception as e:
                print(f"任务执行出错: {e}")
    
    print("\n所有任务完成")

if __name__ == "__main__":
    thread_pool_demo()

# 输出示例：
# === ThreadPoolExecutor 线程池 ===
# 线程池最大工作线程数: 3
#
# --- 提交CPU密集型任务 ---
# 任务 0 在线程 123456 开始执行
# 任务 1 在线程 123457 开始执行
# 任务 2 在线程 123458 开始执行
#
# --- 提交I/O密集型任务 ---
# 任务 0 完成，结果: 333333500000
# 任务 3 在线程 123456 开始执行
# ...（后续输出）
# 所有任务完成
```

### 6.2 线程池异常处理
```python
import concurrent.futures
import threading
import time
import random

def potentially_failing_task(task_id):
    """可能失败的任务"""
    print(f"任务 {task_id} 开始执行")
    
    # 模拟随机失败
    if random.random() < 0.3:  # 30%的失败率
        raise ValueError(f"任务 {task_id} 执行失败!")
    
    # 模拟工作
    time.sleep(random.uniform(0.5, 1.0))
    
    result = f"任务 {task_id} 成功完成"
    print(result)
    return result

def robust_worker(task_id):
    """健壮的worker函数，处理异常"""
    try:
        return potentially_failing_task(task_id)
    except Exception as e:
        return f"任务 {task_id} 捕获异常: {e}"

def exception_handling_demo():
    """异常处理演示"""
    print("=== 线程池异常处理 ===")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        # 提交任务
        futures = [
            executor.submit(robust_worker, i)
            for i in range(8)
        ]
        
        # 处理结果
        success_count = 0
        failure_count = 0
        
        for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                if "异常" in result:
                    failure_count += 1
                    print(f"失败: {result}")
                else:
                    success_count += 1
                    print(f"成功: {result}")
            except Exception as e:
                failure_count += 1
                print(f"未来对象异常: {e}")
        
        print(f"\n统计: 成功 {success_count} 个, 失败 {failure_count} 个")

if __name__ == "__main__":
    exception_handling_demo()

# 输出示例：
# === 线程池异常处理 ===
# 任务 0 开始执行
# 任务 1 开始执行
# 任务 0 成功完成
# 成功: 任务 0 成功完成
# 任务 2 开始执行
# 任务 1 成功完成
# 成功: 任务 1 成功完成
# 任务 3 开始执行
# 任务 2 执行失败!
# 失败: 任务 2 捕获异常: 任务 2 执行失败!
# ...（后续输出）
# 统计: 成功 5 个, 失败 3 个
```

## 7. 定时器和后台线程

### 7.1 使用Timer执行定时任务
```python
import threading
import time
import datetime

def scheduled_task(task_name, execution_count=[0]):
    """定时执行的任务"""
    execution_count[0] += 1
    current_time = datetime.datetime.now().strftime("%H:%M:%S")
    print(f"[{current_time}] 定时任务 '{task_name}' 第 {execution_count[0]} 次执行")

def timer_demo():
    """定时器演示"""
    print("=== Timer定时器 ===")
    
    # 创建一次性定时器（5秒后执行）
    one_time_timer = threading.Timer(
        5.0, 
        scheduled_task, 
        args=("一次性任务",)
    )
    one_time_timer.start()
    print("一次性定时器已启动，5秒后执行")
    
    # 创建周期性定时器
    def start_periodic_timer():
        """启动周期性定时器"""
        scheduled_task("周期性任务")
        # 每次执行后重新启动定时器
        periodic_timer = threading.Timer(3.0, start_periodic_timer)
        periodic_timer.daemon = True  # 设置为守护线程
        periodic_timer.start()
    
    # 启动第一个周期性定时器
    periodic_timer = threading.Timer(2.0, start_periodic_timer)
    periodic_timer.daemon = True
    periodic_timer.start()
    print("周期性定时器已启动，2秒后开始每3秒执行一次")
    
    # 等待一次性定时器完成
    one_time_timer.join()
    print("一次性定时器完成")
    
    # 让主线程运行一段时间以观察周期性定时器
    print("主线程等待10秒...")
    time.sleep(10)
    print("演示结束")

if __name__ == "__main__":
    timer_demo()

# 输出示例：
# === Timer定时器 ===
# 一次性定时器已启动，5秒后执行
# 周期性定时器已启动，2秒后开始每3秒执行一次
# 主线程等待10秒...
# [14:30:02] 定时任务 '周期性任务' 第 1 次执行
# [14:30:05] 定时任务 '周期性任务' 第 2 次执行
# [14:30:06] 定时任务 '一次性任务' 第 1 次执行
# 一次性定时器完成
# [14:30:08] 定时任务 '周期性任务' 第 3 次执行
# [14:30:11] 定时任务 '周期性任务' 第 4 次执行
# 演示结束
```

### 7.2 守护线程
```python
import threading
import time
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def daemon_worker(worker_id):
    """守护线程工作函数"""
    count = 0
    while True:
        count += 1
        logging.info(f"守护线程 {worker_id} 运行中... (计数: {count})")
        time.sleep(1)

def normal_worker(worker_id, duration):
    """普通线程工作函数"""
    logging.info(f"普通线程 {worker_id} 开始执行")
    
    for i in range(duration):
        logging.info(f"普通线程 {worker_id} 执行第 {i+1}/{duration} 步")
        time.sleep(1)
    
    logging.info(f"普通线程 {worker_id} 完成执行")

def daemon_demo():
    """守护线程演示"""
    print("=== 守护线程(Daemon Thread) ===")
    
    # 创建守护线程
    daemon_thread = threading.Thread(
        target=daemon_worker,
        args=("Daemon-1",),
        daemon=True  # 设置为守护线程
    )
    daemon_thread.start()
    logging.info("守护线程已启动")
    
    # 创建普通线程
    normal_thread = threading.Thread(
        target=normal_worker,
        args=("Normal-1", 3)
    )
    normal_thread.start()
    logging.info("普通线程已启动")
    
    # 等待普通线程完成
    normal_thread.join()
    logging.info("普通线程已完成")
    
    # 此时只有守护线程在运行
    logging.info("主线程等待2秒...")
    time.sleep(2)
    
    logging.info("主线程结束，守护线程也会自动结束")

if __name__ == "__main__":
    daemon_demo()

# 输出示例：
# === 守护线程(Daemon Thread) ===
# 2024-01-01 10:00:00,000 - INFO - 守护线程已启动
# 2024-01-01 10:00:00,001 - INFO - 普通线程已启动
# 2024-01-01 10:00:00,001 - INFO - 守护线程 Daemon-1 运行中... (计数: 1)
# 2024-01-01 10:00:00,001 - INFO - 普通线程 Normal-1 开始执行
# 2024-01-01 10:00:00,001 - INFO - 普通线程 Normal-1 执行第 1/3 步
# 2024-01-01 10:00:01,002 - INFO - 守护线程 Daemon-1 运行中... (计数: 2)
# 2024-01-01 10:00:01,002 - INFO - 普通线程 Normal-1 执行第 2/3 步
# ...（后续输出）
# 2024-01-01 10:00:03,004 - INFO - 普通线程 Normal-1 完成执行
# 2024-01-01 10:00:03,004 - INFO - 普通线程已完成
# 2024-01-01 10:00:03,004 - INFO - 主线程等待2秒...
# 2024-01-01 10:00:04,005 - INFO - 守护线程 Daemon-1 运行中... (计数: 4)
# 2024-01-01 10:00:05,005 - INFO - 主线程结束，守护线程也会自动结束
```

## 8. 高级主题：GIL（全局解释器锁）

### 8.1 GIL的影响和应对策略
```python
import threading
import time
import multiprocessing

def cpu_bound_work(n):
    """CPU密集型工作"""
    count = 0
    for i in range(n):
        count += i * i
    return count

def io_bound_work(duration):
    """I/O密集型工作"""
    time.sleep(duration)
    return duration

def test_gil_impact():
    """测试GIL对性能的影响"""
    print("=== GIL（全局解释器锁）影响测试 ===")
    
    # 测试参数
    work_size = 10000000
    sleep_duration = 1
    
    # 单线程CPU密集型工作
    print("\n--- 单线程CPU密集型 ---")
    start_time = time.time()
    result1 = cpu_bound_work(work_size)
    result2 = cpu_bound_work(work_size)
    single_thread_time = time.time() - start_time
    print(f"单线程时间: {single_thread_time:.2f} 秒")
    
    # 多线程CPU密集型工作
    print("\n--- 多线程CPU密集型 ---")
    start_time = time.time()
    
    thread1 = threading.Thread(target=cpu_bound_work, args=(work_size,))
    thread2 = threading.Thread(target=cpu_bound_work, args=(work_size,))
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    multi_thread_time = time.time() - start_time
    print(f"多线程时间: {multi_thread_time:.2f} 秒")
    print(f"加速比: {single_thread_time / multi_thread_time:.2f}x")
    
    # 多进程CPU密集型工作（对比）
    print("\n--- 多进程CPU密集型 ---")
    start_time = time.time()
    
    with multiprocessing.Pool(2) as pool:
        results = pool.map(cpu_bound_work, [work_size, work_size])
    
    multi_process_time = time.time() - start_time
    print(f"多进程时间: {multi_process_time:.2f} 秒")
    print(f"加速比: {single_thread_time / multi_process_time:.2f}x")
    
    # I/O密集型工作对比
    print("\n--- I/O密集型工作对比 ---")
    
    # 单线程I/O
    start_time = time.time()
    io_bound_work(sleep_duration)
    io_bound_work(sleep_duration)
    single_io_time = time.time() - start_time
    print(f"单线程I/O时间: {single_io_time:.2f} 秒")
    
    # 多线程I/O
    start_time = time.time()
    
    thread1 = threading.Thread(target=io_bound_work, args=(sleep_duration,))
    thread2 = threading.Thread(target=io_bound_work, args=(sleep_duration,))
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    multi_io_time = time.time() - start_time
    print(f"多线程I/O时间: {multi_io_time:.2f} 秒")
    print(f"加速比: {single_io_time / multi_io_time:.2f}x")

if __name__ == "__main__":
    test_gil_impact()

# 输出示例：
# === GIL（全局解释器锁）影响测试 ===
#
# --- 单线程CPU密集型 ---
# 单线程时间: 2.45 秒
#
# --- 多线程CPU密集型 ---
# 多线程时间: 2.51 秒  # 由于GIL，多线程可能更慢
# 加速比: 0.98x
#
# --- 多进程CPU密集型 ---
# 多进程时间: 1.32 秒  # 多进程真正并行
# 加速比: 1.86x
#
# --- I/O密集型工作对比 ---
# 单线程I/O时间: 2.00 秒
# 多线程I/O时间: 1.00 秒  # I/O操作释放GIL，多线程有效
# 加速比: 2.00x
```

## 9. 常见易错点和最佳实践

### 9.1 死锁预防和调试
```python
import threading
import time
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

def create_deadlock():
    """创建死锁的示例"""
    lock_a = threading.Lock()
    lock_b = threading.Lock()
    
    def worker1():
        logging.info("Worker1 尝试获取锁A")
        lock_a.acquire()
        logging.info("Worker1 获得锁A")
        
        time.sleep(0.1)  # 让Worker2有机会获取锁B
        
        logging.info("Worker1 尝试获取锁B")
        lock_b.acquire()  # 这里会死锁
        logging.info("Worker1 获得锁B")
        
        # 工作...
        time.sleep(0.1)
        
        lock_b.release()
        lock_a.release()
        logging.info("Worker1 完成")
    
    def worker2():
        logging.info("Worker2 尝试获取锁B")
        lock_b.acquire()
        logging.info("Worker2 获得锁B")
        
        time.sleep(0.1)  # 让Worker1有机会获取锁A
        
        logging.info("Worker2 尝试获取锁A")
        lock_a.acquire()  # 这里会死锁
        logging.info("Worker2 获得锁A")
        
        # 工作...
        time.sleep(0.1)
        
        lock_a.release()
        lock_b.release()
        logging.info("Worker2 完成")
    
    # 启动线程
    t1 = threading.Thread(target=worker1)
    t2 = threading.Thread(target=worker2)
    
    t1.start()
    t2.start()
    
    # 设置超时，避免永久阻塞
    t1.join(timeout=3)
    t2.join(timeout=3)
    
    if t1.is_alive() or t2.is_alive():
        logging.error("检测到死锁！强制终止线程")
        # 在实际应用中应该使用更优雅的方式处理

def prevent_deadlock():
    """预防死锁的示例"""
    lock_a = threading.Lock()
    lock_b = threading.Lock()
    
    def worker1():
        # 总是按相同顺序获取锁
        logging.info("Worker1 尝试获取锁A")
        with lock_a:
            logging.info("Worker1 获得锁A")
            
            time.sleep(0.1)
            
            logging.info("Worker1 尝试获取锁B")
            with lock_b:
                logging.info("Worker1 获得锁B")
                
                # 工作...
                time.sleep(0.1)
        
        logging.info("Worker1 完成")
    
    def worker2():
        # 总是按相同顺序获取锁（与worker1相同）
        logging.info("Worker2 尝试获取锁A")
        with lock_a:
            logging.info("Worker2 获得锁A")
            
            time.sleep(0.1)
            
            logging.info("Worker2 尝试获取锁B")
            with lock_b:
                logging.info("Worker2 获得锁B")
                
                # 工作...
                time.sleep(0.1)
        
        logging.info("Worker2 完成")
    
    # 启动线程
    t1 = threading.Thread(target=worker1)
    t2 = threading.Thread(target=worker2)
    
    t1.start()
    t2.start()
    
    t1.join()
    t2.join()
    
    logging.info("无死锁完成")

if __name__ == "__main__":
    print("=== 死锁预防和调试 ===")
    
    print("\n--- 死锁示例 ---")
    create_deadlock()
    
    print("\n--- 死锁预防 ---")
    prevent_deadlock()

# 输出示例：
# === 死锁预防和调试 ===
#
# --- 死锁示例 ---
# 2024-01-01 10:00:00 - Worker1 尝试获取锁A
# 2024-01-01 10:00:00 - Worker1 获得锁A
# 2024-01-01 10:00:00 - Worker2 尝试获取锁B
# 2024-01-01 10:00:00 - Worker2 获得锁B
# 2024-01-01 10:00:00 - Worker1 尝试获取锁B
# 2024-01-01 10:00:00 - Worker2 尝试获取锁A
# 2024-01-01 10:00:03 - 检测到死锁！强制终止线程
#
# --- 死锁预防 ---
# 2024-01-01 10:00:03 - Worker1 尝试获取锁A
# 2024-01-01 10:00:03 - Worker1 获得锁A
# 2024-01-01 10:00:03 - Worker2 尝试获取锁A
# 2024-01-01 10:00:03 - Worker1 尝试获取锁B
# 2024-01-01 10:00:03 - Worker1 获得锁B
# ...（正常执行）
# 2024-01-01 10:00:04 - 无死锁完成
```

### 9.2 资源泄漏预防
```python
import threading
import weakref
import time
import gc

class ResourceManager:
    """资源管理器，演示资源泄漏和预防"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._resources = weakref.WeakSet()
                cls._instance._lock = threading.Lock()
        return cls._instance
    
    def register_resource(self, resource):
        """注册资源（使用弱引用）"""
        with self._lock:
            self._resources.add(resource)
    
    def get_resource_count(self):
        """获取当前资源数量"""
        with self._lock:
            return len(self._resources)
    
    def list_resources(self):
        """列出所有资源"""
        with self._lock:
            return list(self._resources)

class ExpensiveResource:
    """昂贵的资源类"""
    
    def __init__(self, resource_id):
        self.resource_id = resource_id
        self.data = "x" * 1024 * 1024  # 1MB数据，模拟昂贵资源
        self.manager = ResourceManager()
        self.manager.register_resource(self)
        print(f"创建资源 {resource_id}")
    
    def __del__(self):
        print(f"销毁资源 {self.resource_id}")
    
    def use_resource(self):
        """使用资源"""
        print(f"使用资源 {self.resource_id}")

def worker_with_leak(worker_id):
    """可能造成资源泄漏的worker"""
    # 创建资源但忘记清理
    resource = ExpensiveResource(f"Leaky-{worker_id}")
    resource.use_resource()
    # 注意：没有显式删除resource，但Python会垃圾回收

def worker_proper(worker_id):
    """正确管理资源的worker"""
    resource = ExpensiveResource(f"Proper-{worker_id}")
    try:
        resource.use_resource()
    finally:
        # 显式删除引用，帮助垃圾回收
        del resource

def resource_leak_demo():
    """资源泄漏演示"""
    print("=== 资源泄漏预防 ===")
    
    manager = ResourceManager()
    
    print(f"初始资源数量: {manager.get_resource_count()}")
    
    # 创建可能泄漏的worker
    print("\n--- 创建可能泄漏的worker ---")
    threads = []
    for i in range(3):
        t = threading.Thread(target=worker_with_leak, args=(i,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"创建后资源数量: {manager.get_resource_count()}")
    
    # 强制垃圾回收
    print("\n--- 执行垃圾回收 ---")
    gc.collect()
    time.sleep(0.1)  # 给垃圾回收一些时间
    
    print(f"垃圾回收后资源数量: {manager.get_resource_count()}")
    
    # 创建正确管理的worker
    print("\n--- 创建正确管理的worker ---")
    threads = []
    for i in range(3):
        t = threading.Thread(target=worker_proper, args=(i,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"创建后资源数量: {manager.get_resource_count()}")
    
    # 强制垃圾回收
    print("\n--- 执行垃圾回收 ---")
    gc.collect()
    time.sleep(0.1)
    
    print(f"垃圾回收后资源数量: {manager.get_resource_count()}")

if __name__ == "__main__":
    resource_leak_demo()

# 输出示例：
# === 资源泄漏预防 ===
# 初始资源数量: 0
#
# --- 创建可能泄漏的worker ---
# 创建资源 Leaky-0
# 使用资源 Leaky-0
# 创建资源 Leaky-1
# 使用资源 Leaky-1
# 创建资源 Leaky-2
# 使用资源 Leaky-2
# 创建后资源数量: 3
#
# --- 执行垃圾回收 ---
# 销毁资源 Leaky-0
# 销毁资源 Leaky-1
# 销毁资源 Leaky-2
# 垃圾回收后资源数量: 0
#
# --- 创建正确管理的worker ---
# 创建资源 Proper-0
# 使用资源 Proper-0
# 销毁资源 Proper-0
# ...（后续输出）
# 垃圾回收后资源数量: 0
```

这个超详细的Python线程编程笔记涵盖了：

1. 线程基础概念和与进程的区别
2. 多种创建和管理线程的方式
3. 线程同步机制（Lock、RLock、Semaphore、Event、Condition）
4. 线程间通信（Queue）
5. 线程局部数据
6. 线程池的使用
7. 定时器和守护线程
8. GIL的影响和应对策略
9. 常见易错点和最佳实践

每个概念都配有详细的代码示例和注释，输出结果以注释形式展示，适合系统学习Python多线程编程。