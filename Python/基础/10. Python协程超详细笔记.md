# Python协程超详细笔记

## 1. 协程基础概念

### 1.1 什么是协程
```python
"""
协程（Coroutine）：一种用户态的轻量级线程，由用户控制调度
- 可以在单个线程内实现并发
- 通过async/await语法实现
- 遇到IO操作时自动切换，提高效率
"""

import asyncio
import time

# 传统的同步函数
def sync_hello():
    print("Hello")
    time.sleep(1)  # 阻塞调用
    print("World")

# 异步协程函数
async def async_hello():
    print("Hello")
    await asyncio.sleep(1)  # 非阻塞等待
    print("World")

def compare_sync_async():
    """比较同步和异步执行"""
    print("=== 同步执行 ===")
    start = time.time()
    sync_hello()
    sync_hello()
    print(f"同步执行时间: {time.time() - start:.2f}秒")
    
    print("\n=== 异步执行 ===")
    start = time.time()
    # 运行异步函数
    asyncio.run(async_hello())
    asyncio.run(async_hello())
    print(f"异步执行时间: {time.time() - start:.2f}秒")

if __name__ == "__main__":
    compare_sync_async()

# 输出：
# === 同步执行 ===
# Hello
# World
# Hello
# World
# 同步执行时间: 2.00秒
#
# === 异步执行 ===
# Hello
# World
# Hello
# World
# 异步执行时间: 2.00秒（注意：这里没有并发，后面会改进）
```

### 1.2 协程 vs 线程 vs 进程
```python
import asyncio
import threading
import multiprocessing
import time

def cpu_bound_sync(n):
    """CPU密集型同步任务"""
    return sum(i * i for i in range(n))

async def cpu_bound_async(n):
    """CPU密集型异步任务（实际上不会更快）"""
    return sum(i * i for i in range(n))

def io_bound_sync(duration):
    """I/O密集型同步任务"""
    time.sleep(duration)
    return f"同步任务完成，耗时{duration}秒"

async def io_bound_async(duration):
    """I/O密集型异步任务"""
    await asyncio.sleep(duration)
    return f"异步任务完成，耗时{duration}秒"

async def compare_concurrency():
    """比较不同并发模型"""
    print("=== 并发模型比较 ===")
    
    # 测试参数
    n = 10**7
    sleep_time = 1
    
    # 同步执行基准
    print("\n--- 同步执行 ---")
    start = time.time()
    result1 = cpu_bound_sync(n)
    result2 = cpu_bound_sync(n)
    sync_time = time.time() - start
    print(f"同步CPU任务时间: {sync_time:.2f}秒")
    
    # 异步执行（CPU密集型）
    print("\n--- 异步执行(CPU密集型) ---")
    start = time.time()
    task1 = cpu_bound_async(n)
    task2 = cpu_bound_async(n)
    results = await asyncio.gather(task1, task2)
    async_cpu_time = time.time() - start
    print(f"异步CPU任务时间: {async_cpu_time:.2f}秒")
    
    # 异步执行（I/O密集型）
    print("\n--- 异步执行(I/O密集型) ---")
    start = time.time()
    task1 = io_bound_async(sleep_time)
    task2 = io_bound_async(sleep_time)
    results = await asyncio.gather(task1, task2)
    async_io_time = time.time() - start
    print(f"异步I/O任务时间: {async_io_time:.2f}秒")
    
    # 多线程执行
    print("\n--- 多线程执行 ---")
    start = time.time()
    thread1 = threading.Thread(target=io_bound_sync, args=(sleep_time,))
    thread2 = threading.Thread(target=io_bound_sync, args=(sleep_time,))
    thread1.start()
    thread2.start()
    thread1.join()
    thread2.join()
    thread_time = time.time() - start
    print(f"多线程任务时间: {thread_time:.2f}秒")
    
    print(f"\n总结:")
    print(f"CPU密集型: 同步 {sync_time:.2f}s vs 异步 {async_cpu_time:.2f}s")
    print(f"I/O密集型: 异步 {async_io_time:.2f}s vs 多线程 {thread_time:.2f}s")

# 运行比较
if __name__ == "__main__":
    asyncio.run(compare_concurrency())

# 输出示例：
# === 并发模型比较 ===
#
# --- 同步执行 ---
# 同步CPU任务时间: 1.23秒
#
# --- 异步执行(CPU密集型) ---
# 异步CPU任务时间: 2.45秒  # 注意：异步不会加速CPU密集型任务
#
# --- 异步执行(I/O密集型) ---
# 异步I/O任务时间: 1.00秒  # 异步在I/O密集型任务中表现出色
#
# --- 多线程执行 ---
# 多线程任务时间: 1.00秒
#
# 总结:
# CPU密集型: 同步 1.23s vs 异步 2.45s
# I/O密集型: 异步 1.00s vs 多线程 1.00s
```

## 2. asyncio基础

### 2.1 事件循环（Event Loop）
```python
import asyncio
import time

async def simple_coroutine(name, duration):
    """简单的协程示例"""
    print(f"[{time.strftime('%X')}] 协程 {name} 开始")
    await asyncio.sleep(duration)
    print(f"[{time.strftime('%X')}] 协程 {name} 结束")
    return f"{name}_结果"

def event_loop_basics():
    """事件循环基础"""
    print("=== 事件循环基础 ===")
    
    # 方式1：使用asyncio.run（推荐）
    print("\n--- 方式1: asyncio.run ---")
    result = asyncio.run(simple_coroutine("Task1", 1))
    print(f"结果: {result}")
    
    # 方式2：手动管理事件循环
    print("\n--- 方式2: 手动管理事件循环 ---")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        # 运行单个协程
        result = loop.run_until_complete(simple_coroutine("Task2", 1))
        print(f"结果: {result}")
        
        # 运行多个协程
        print("\n--- 运行多个协程 ---")
        tasks = [
            simple_coroutine("TaskA", 2),
            simple_coroutine("TaskB", 1),
            simple_coroutine("TaskC", 3)
        ]
        results = loop.run_until_complete(asyncio.gather(*tasks))
        print(f"所有结果: {results}")
        
    finally:
        loop.close()

if __name__ == "__main__":
    event_loop_basics()

# 输出示例：
# === 事件循环基础 ===
#
# --- 方式1: asyncio.run ---
# [10:00:00] 协程 Task1 开始
# [10:00:01] 协程 Task1 结束
# 结果: Task1_结果
#
# --- 方式2: 手动管理事件循环 ---
# [10:00:01] 协程 Task2 开始
# [10:00:02] 协程 Task2 结束
# 结果: Task2_结果
#
# --- 运行多个协程 ---
# [10:00:02] 协程 TaskA 开始
# [10:00:02] 协程 TaskB 开始
# [10:00:02] 协程 TaskC 开始
# [10:00:03] 协程 TaskB 结束
# [10:00:04] 协程 TaskA 结束
# [10:00:05] 协程 TaskC 结束
# 所有结果: ['TaskA_结果', 'TaskB_结果', 'TaskC_结果']
```

### 2.2 创建和运行协程
```python
import asyncio

async def basic_coroutine(x):
    """基础协程函数"""
    print(f"开始计算 {x}")
    await asyncio.sleep(1)  # 模拟I/O操作
    result = x * x
    print(f"计算完成 {x} -> {result}")
    return result

async def multiple_coroutines():
    """运行多个协程"""
    print("=== 运行多个协程 ===")
    
    # 方式1：依次运行（不推荐）
    print("\n--- 方式1: 依次运行 ---")
    start_time = asyncio.get_event_loop().time()
    result1 = await basic_coroutine(2)
    result2 = await basic_coroutine(3)
    end_time = asyncio.get_event_loop().time()
    print(f"依次运行时间: {end_time - start_time:.2f}秒")
    
    # 方式2：并发运行（推荐）
    print("\n--- 方式2: 并发运行 ---")
    start_time = asyncio.get_event_loop().time()
    task1 = asyncio.create_task(basic_coroutine(4))
    task2 = asyncio.create_task(basic_coroutine(5))
    result1 = await task1
    result2 = await task2
    end_time = asyncio.get_event_loop().time()
    print(f"并发运行时间: {end_time - start_time:.2f}秒")
    
    # 方式3：使用gather
    print("\n--- 方式3: 使用gather ---")
    start_time = asyncio.get_event_loop().time()
    results = await asyncio.gather(
        basic_coroutine(6),
        basic_coroutine(7),
        basic_coroutine(8)
    )
    end_time = asyncio.get_event_loop().time()
    print(f"gather运行时间: {end_time - start_time:.2f}秒")
    print(f"所有结果: {results}")

async def create_task_demo():
    """create_task使用演示"""
    print("\n=== create_task演示 ===")
    
    # 创建任务但不立即等待
    task1 = asyncio.create_task(basic_coroutine(10))
    task2 = asyncio.create_task(basic_coroutine(20))
    
    print("任务已创建，正在执行...")
    
    # 可以在这里执行其他工作
    await asyncio.sleep(0.5)
    print("执行其他工作...")
    
    # 等待任务完成
    result1 = await task1
    result2 = await task2
    
    print(f"任务结果: {result1}, {result2}")

if __name__ == "__main__":
    # 运行演示
    asyncio.run(multiple_coroutines())
    asyncio.run(create_task_demo())

# 输出示例：
# === 运行多个协程 ===
#
# --- 方式1: 依次运行 ---
# 开始计算 2
# 计算完成 2 -> 4
# 开始计算 3
# 计算完成 3 -> 9
# 依次运行时间: 2.00秒
#
# --- 方式2: 并发运行 ---
# 开始计算 4
# 开始计算 5
# 计算完成 4 -> 16
# 计算完成 5 -> 25
# 并发运行时间: 1.00秒
#
# --- 方式3: 使用gather ---
# 开始计算 6
# 开始计算 7
# 开始计算 8
# 计算完成 6 -> 36
# 计算完成 7 -> 49
# 计算完成 8 -> 64
# gather运行时间: 1.00秒
# 所有结果: [36, 49, 64]
#
# === create_task演示 ===
# 任务已创建，正在执行...
# 开始计算 10
# 开始计算 20
# 执行其他工作...
# 计算完成 10 -> 100
# 计算完成 20 -> 400
# 任务结果: 100, 400
```

## 3. 异步控制流

### 3.1 异步迭代器
```python
import asyncio
import random

class AsyncCounter:
    """异步迭代器"""
    
    def __init__(self, start, end, delay=0.1):
        self.current = start
        self.end = end
        self.delay = delay
    
    def __aiter__(self):
        """返回异步迭代器"""
        return self
    
    async def __anext__(self):
        """返回下一个值"""
        if self.current >= self.end:
            raise StopAsyncIteration
        
        # 模拟异步操作
        await asyncio.sleep(self.delay)
        
        value = self.current
        self.current += 1
        return value

async def async_iterator_demo():
    """异步迭代器演示"""
    print("=== 异步迭代器 ===")
    
    # 使用异步for循环
    print("异步计数:")
    async for number in AsyncCounter(1, 6, 0.2):
        print(f"计数: {number}")
    
    # 异步列表推导式
    print("\n异步列表推导式:")
    numbers = [num async for num in AsyncCounter(10, 15)]
    print(f"数字列表: {numbers}")

class AsyncDataStream:
    """异步数据流"""
    
    def __init__(self, data_items, delay=0.1):
        self.data_items = data_items
        self.delay = delay
        self.index = 0
    
    async def stream_data(self):
        """流式生成数据"""
        while self.index < len(self.data_items):
            # 模拟数据处理时间
            await asyncio.sleep(self.delay)
            
            item = self.data_items[self.index]
            self.index += 1
            
            # 使用yield创建异步生成器
            yield item

async def async_generator_demo():
    """异步生成器演示"""
    print("\n=== 异步生成器 ===")
    
    data_stream = AsyncDataStream(["A", "B", "C", "D", "E"], 0.3)
    
    print("流式处理数据:")
    async for item in data_stream.stream_data():
        print(f"处理: {item}")
        
        # 可以在这里添加更多处理逻辑
        await asyncio.sleep(0.1)  # 模拟额外处理

if __name__ == "__main__":
    asyncio.run(async_iterator_demo())
    asyncio.run(async_generator_demo())

# 输出示例：
# === 异步迭代器 ===
# 异步计数:
# 计数: 1
# 计数: 2
# 计数: 3
# 计数: 4
# 计数: 5
#
# 异步列表推导式:
# 数字列表: [10, 11, 12, 13, 14]
#
# === 异步生成器 ===
# 流式处理数据:
# 处理: A
# 处理: B
# 处理: C
# 处理: D
# 处理: E
```

### 3.2 异步上下文管理器
```python
import asyncio

class AsyncDatabaseConnection:
    """异步数据库连接（模拟）"""
    
    def __init__(self, connection_name):
        self.connection_name = connection_name
        self.is_connected = False
    
    async def connect(self):
        """模拟连接数据库"""
        print(f"连接 {self.connection_name}...")
        await asyncio.sleep(0.5)
        self.is_connected = True
        print(f"{self.connection_name} 连接成功")
    
    async def disconnect(self):
        """模拟断开数据库连接"""
        print(f"断开 {self.connection_name}...")
        await asyncio.sleep(0.2)
        self.is_connected = False
        print(f"{self.connection_name} 已断开")
    
    async def execute_query(self, query):
        """执行查询"""
        if not self.is_connected:
            raise RuntimeError("数据库未连接")
        
        print(f"执行查询: {query}")
        await asyncio.sleep(0.3)
        return f"{query}_结果"
    
    async def __aenter__(self):
        """进入上下文时调用"""
        await self.connect()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """退出上下文时调用"""
        await self.disconnect()
        if exc_type:
            print(f"发生错误: {exc_val}")
        return False  # 不抑制异常

async def async_context_demo():
    """异步上下文管理器演示"""
    print("=== 异步上下文管理器 ===")
    
    # 使用async with自动管理资源
    async with AsyncDatabaseConnection("主数据库") as db:
        result1 = await db.execute_query("SELECT * FROM users")
        result2 = await db.execute_query("SELECT COUNT(*) FROM products")
        print(f"查询结果: {result1}, {result2}")
    
    print("数据库连接已自动关闭")

class AsyncTransaction:
    """异步事务管理器"""
    
    def __init__(self, name):
        self.name = name
        self.committed = False
    
    async def __aenter__(self):
        print(f"开始事务: {self.name}")
        await asyncio.sleep(0.1)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            # 没有异常，提交事务
            await self.commit()
        else:
            # 有异常，回滚事务
            await self.rollback()
            print(f"事务 {self.name} 回滚，原因: {exc_val}")
        return False
    
    async def commit(self):
        """提交事务"""
        print(f"提交事务: {self.name}")
        await asyncio.sleep(0.2)
        self.committed = True
    
    async def rollback(self):
        """回滚事务"""
        print(f"回滚事务: {self.name}")
        await asyncio.sleep(0.1)

async def transaction_demo():
    """事务演示"""
    print("\n=== 事务管理 ===")
    
    # 成功的事务
    print("--- 成功事务 ---")
    async with AsyncTransaction("成功事务") as tx:
        await asyncio.sleep(0.1)
        print("执行事务操作...")
    
    # 失败的事务
    print("\n--- 失败事务 ---")
    try:
        async with AsyncTransaction("失败事务") as tx:
            await asyncio.sleep(0.1)
            print("执行事务操作...")
            raise ValueError("模拟的业务错误")
    except ValueError as e:
        print(f"捕获到错误: {e}")

if __name__ == "__main__":
    asyncio.run(async_context_demo())
    asyncio.run(transaction_demo())

# 输出示例：
# === 异步上下文管理器 ===
# 连接 主数据库...
# 主数据库 连接成功
# 执行查询: SELECT * FROM users
# 执行查询: SELECT COUNT(*) FROM products
# 查询结果: SELECT * FROM users_结果, SELECT COUNT(*) FROM products_结果
# 断开 主数据库...
# 主数据库 已断开
# 数据库连接已自动关闭
#
# === 事务管理 ===
# --- 成功事务 ---
# 开始事务: 成功事务
# 执行事务操作...
# 提交事务: 成功事务
#
# --- 失败事务 ---
# 开始事务: 失败事务
# 执行事务操作...
# 回滚事务: 失败事务
# 事务 失败事务 回滚，原因: 模拟的业务错误
# 捕获到错误: 模拟的业务错误
```

## 4. 高级协程模式

### 4.1 生产者-消费者模式
```python
import asyncio
import random
import time

class AsyncQueue:
    """异步队列"""
    
    def __init__(self, maxsize=0):
        self.maxsize = maxsize
        self._queue = asyncio.Queue(maxsize=maxsize)
        self._producer_count = 0
        self._consumer_count = 0
    
    async def produce(self, item, producer_id):
        """生产项目"""
        # 模拟生产时间
        production_time = random.uniform(0.1, 0.5)
        await asyncio.sleep(production_time)
        
        await self._queue.put(item)
        self._producer_count += 1
        
        current_size = self._queue.qsize()
        print(f"[生产者 {producer_id}] 生产: {item} "
              f"(队列大小: {current_size}/{self.maxsize})")
        
        return item
    
    async def consume(self, consumer_id):
        """消费项目"""
        # 等待项目可用
        item = await self._queue.get()
        
        # 模拟消费时间
        consumption_time = random.uniform(0.2, 0.8)
        await asyncio.sleep(consumption_time)
        
        self._consumer_count += 1
        current_size = self._queue.qsize()
        
        print(f"[消费者 {consumer_id}] 消费: {item} "
              f"(队列大小: {current_size}/{self.maxsize})")
        
        # 标记任务完成
        self._queue.task_done()
        
        return item
    
    async def join(self):
        """等待所有项目被处理"""
        await self._queue.join()
    
    def get_stats(self):
        """获取统计信息"""
        return {
            'queue_size': self._queue.qsize(),
            'produced': self._producer_count,
            'consumed': self._consumer_count
        }

async def producer_worker(queue, producer_id, item_count):
    """生产者工作协程"""
    for i in range(item_count):
        item = f"产品_{producer_id}_{i}"
        await queue.produce(item, producer_id)

async def consumer_worker(queue, consumer_id, consume_count):
    """消费者工作协程"""
    for i in range(consume_count):
        item = await queue.consume(consumer_id)
        # 可以在这里处理消费的项目

async def producer_consumer_demo():
    """生产者-消费者演示"""
    print("=== 异步生产者-消费者模式 ===")
    
    # 创建队列（最大容量为5）
    queue = AsyncQueue(maxsize=5)
    
    # 创建生产者
    producers = [
        asyncio.create_task(producer_worker(queue, f"P{i}", 4))
        for i in range(2)
    ]
    
    # 创建消费者
    consumers = [
        asyncio.create_task(consumer_worker(queue, f"C{i}", 3))
        for i in range(3)
    ]
    
    # 等待所有生产者完成
    await asyncio.gather(*producers)
    print("所有生产者完成")
    
    # 等待队列清空
    await queue.join()
    print("队列已清空")
    
    # 取消消费者（因为可能还在等待）
    for consumer in consumers:
        consumer.cancel()
    
    # 获取统计信息
    stats = queue.get_stats()
    print(f"\n统计信息: {stats}")

if __name__ == "__main__":
    asyncio.run(producer_consumer_demo())

# 输出示例：
# === 异步生产者-消费者模式 ===
# [生产者 P0] 生产: 产品_P0_0 (队列大小: 1/5)
# [生产者 P1] 生产: 产品_P1_0 (队列大小: 2/5)
# [消费者 C0] 消费: 产品_P0_0 (队列大小: 1/5)
# [生产者 P0] 生产: 产品_P0_1 (队列大小: 2/5)
# [消费者 C1] 消费: 产品_P1_0 (队列大小: 1/5)
# ...（后续输出）
# 所有生产者完成
# 队列已清空
#
# 统计信息: {'queue_size': 0, 'produced': 8, 'consumed': 8}
```

### 4.2 异步限流器
```python
import asyncio
import time

class AsyncRateLimiter:
    """异步限流器"""
    
    def __init__(self, rate, period=1.0):
        """
        rate: 每秒允许的请求数
        period: 时间窗口（秒）
        """
        self.rate = rate
        self.period = period
        self.tokens = rate
        self.last_update = time.monotonic()
        self._lock = asyncio.Lock()
    
    async def acquire(self):
        """获取令牌"""
        async with self._lock:
            now = time.monotonic()
            elapsed = now - self.last_update
            
            # 补充令牌
            self.tokens += elapsed * (self.rate / self.period)
            if self.tokens > self.rate:
                self.tokens = self.rate
            
            self.last_update = now
            
            if self.tokens >= 1:
                # 有足够的令牌
                self.tokens -= 1
                return True
            else:
                # 需要等待
                wait_time = (1 - self.tokens) * (self.period / self.rate)
                self.tokens = 0
                await asyncio.sleep(wait_time)
                self.last_update = time.monotonic()
                return True

class AsyncSemaphore:
    """异步信号量（带超时）"""
    
    def __init__(self, value=1):
        self._value = value
        self._waiters = []
    
    async def acquire(self, timeout=None):
        """获取信号量"""
        while self._value <= 0:
            # 需要等待
            fut = asyncio.get_event_loop().create_future()
            self._waiters.append(fut)
            
            try:
                if timeout is None:
                    await fut
                else:
                    await asyncio.wait_for(fut, timeout)
            except asyncio.TimeoutError:
                self._waiters.remove(fut)
                raise
            except:
                self._waiters.remove(fut)
                raise
        
        self._value -= 1
        return True
    
    def release(self):
        """释放信号量"""
        self._value += 1
        if self._waiters:
            # 唤醒一个等待者
            fut = self._waiters.pop(0)
            fut.set_result(True)
    
    async def __aenter__(self):
        await self.acquire()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.release()
        return False

async def rate_limited_worker(limiter, worker_id, task_count):
    """限流的工作协程"""
    for i in range(task_count):
        # 获取限流许可
        await limiter.acquire()
        
        # 执行任务
        print(f"[{time.strftime('%X')}] 工作器 {worker_id} 执行任务 {i}")
        await asyncio.sleep(0.1)  # 模拟工作

async def semaphore_worker(semaphore, worker_id, task_count):
    """使用信号量的工作协程"""
    for i in range(task_count):
        try:
            async with semaphore:
                print(f"[{time.strftime('%X')}] 工作器 {worker_id} 获取信号量，执行任务 {i}")
                await asyncio.sleep(0.5)  # 模拟工作
        except asyncio.TimeoutError:
            print(f"工作器 {worker_id} 获取信号量超时")

async def rate_limiter_demo():
    """限流器演示"""
    print("=== 异步限流器 ===")
    
    # 创建限流器（每秒2个请求）
    limiter = AsyncRateLimiter(rate=2, period=1.0)
    
    # 创建工作协程
    workers = [
        rate_limited_worker(limiter, f"W{i}", 3)
        for i in range(3)
    ]
    
    print("开始限流测试...")
    await asyncio.gather(*workers)
    print("限流测试完成")

async def semaphore_demo():
    """信号量演示"""
    print("\n=== 异步信号量 ===")
    
    # 创建信号量（允许2个并发）
    semaphore = AsyncSemaphore(2)
    
    # 创建工作协程
    workers = [
        semaphore_worker(semaphore, f"S{i}", 3)
        for i in range(4)
    ]
    
    print("开始信号量测试...")
    await asyncio.gather(*workers)
    print("信号量测试完成")

if __name__ == "__main__":
    asyncio.run(rate_limiter_demo())
    asyncio.run(semaphore_demo())

# 输出示例：
# === 异步限流器 ===
# 开始限流测试...
# [10:00:00] 工作器 W0 执行任务 0
# [10:00:00] 工作器 W1 执行任务 0
# [10:00:01] 工作器 W2 执行任务 0
# [10:00:01] 工作器 W0 执行任务 1
# [10:00:02] 工作器 W1 执行任务 1
# ...（每秒最多2个任务）
# 限流测试完成
#
# === 异步信号量 ===
# 开始信号量测试...
# [10:00:03] 工作器 S0 获取信号量，执行任务 0
# [10:00:03] 工作器 S1 获取信号量，执行任务 0
# [10:00:04] 工作器 S2 获取信号量，执行任务 0
# [10:00:04] 工作器 S3 获取信号量，执行任务 0
# ...（最多2个并发）
# 信号量测试完成
```

## 5. 错误处理和调试

### 5.1 协程异常处理
```python
import asyncio
import random

async def unreliable_coroutine(task_id, success_rate=0.7):
    """不可靠的协程，可能失败"""
    print(f"任务 {task_id} 开始执行")
    await asyncio.sleep(0.5)
    
    if random.random() > success_rate:
        raise ValueError(f"任务 {task_id} 执行失败!")
    
    result = f"任务 {task_id} 成功完成"
    print(result)
    return result

async def robust_worker(task_id, retries=3):
    """健壮的工作协程，带重试机制"""
    for attempt in range(retries):
        try:
            result = await unreliable_coroutine(f"{task_id}_尝试{attempt+1}")
            return result
        except ValueError as e:
            print(f"任务 {task_id} 第 {attempt+1} 次尝试失败: {e}")
            if attempt < retries - 1:
                wait_time = (attempt + 1) * 0.5  # 指数退避
                print(f"等待 {wait_time} 秒后重试...")
                await asyncio.sleep(wait_time)
            else:
                print(f"任务 {task_id} 所有重试均失败")
                raise

async def error_handling_demo():
    """错误处理演示"""
    print("=== 协程错误处理 ===")
    
    # 方式1：单独处理每个协程
    print("\n--- 方式1: 单独处理 ---")
    tasks = []
    for i in range(4):
        task = asyncio.create_task(unreliable_coroutine(f"Single_{i}", 0.5))
        tasks.append(task)
    
    for task in tasks:
        try:
            result = await task
            print(f"成功: {result}")
        except ValueError as e:
            print(f"失败: {e}")
    
    # 方式2：使用gather的return_exceptions
    print("\n--- 方式2: gather统一处理 ---")
    tasks = [
        unreliable_coroutine(f"Gather_{i}", 0.6)
        for i in range(4)
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"任务 {i} 异常: {result}")
        else:
            print(f"任务 {i} 成功: {result}")
    
    # 方式3：带重试的健壮worker
    print("\n--- 方式3: 带重试机制 ---")
    try:
        result = await robust_worker("RobustTask")
        print(f"最终结果: {result}")
    except ValueError as e:
        print(f"最终失败: {e}")

async def timeout_demo():
    """超时处理演示"""
    print("\n=== 超时处理 ===")
    
    async def slow_coroutine(duration, name):
        print(f"慢协程 {name} 开始，需要 {duration} 秒")
        await asyncio.sleep(duration)
        return f"慢协程 {name} 完成"
    
    # 使用wait_for设置超时
    try:
        result = await asyncio.wait_for(
            slow_coroutine(3, "TimeoutTest"), 
            timeout=1.5
        )
        print(f"结果: {result}")
    except asyncio.TimeoutError:
        print("任务超时！")
    
    # 使用asyncio.shield防止取消
    print("\n--- 使用shield防止取消 ---")
    slow_task = asyncio.create_task(slow_coroutine(2, "ShieldedTask"))
    
    try:
        # shield保护任务不被取消
        result = await asyncio.wait_for(
            asyncio.shield(slow_task),
            timeout=1.0
        )
        print(f"结果: {result}")
    except asyncio.TimeoutError:
        print("外部超时，但任务继续运行...")
        # 等待被shield的任务完成
        result = await slow_task
        print(f"被保护的任务最终完成: {result}")

if __name__ == "__main__":
    asyncio.run(error_handling_demo())
    asyncio.run(timeout_demo())

# 输出示例：
# === 协程错误处理 ===
#
# --- 方式1: 单独处理 ---
# 任务 Single_0 开始执行
# 任务 Single_1 开始执行
# 任务 Single_2 开始执行
# 任务 Single_3 开始执行
# 任务 Single_0 执行失败!
# 任务 Single_1 成功完成
# 失败: 任务 Single_0 执行失败!
# 成功: 任务 Single_1 成功完成
# ...（后续输出）
#
# --- 方式2: gather统一处理 ---
# 任务 Gather_0 开始执行
# ...（后续输出）
# 任务 0 成功: 任务 Gather_0 成功完成
# 任务 1 异常: 任务 Gather_1 执行失败!
#
# --- 方式3: 带重试机制 ---
# 任务 RobustTask_尝试1 开始执行
# 任务 RobustTask 第 1 次尝试失败: 任务 RobustTask_尝试1 执行失败!
# 等待 0.5 秒后重试...
# 任务 RobustTask_尝试2 开始执行
# 任务 RobustTask_尝试2 成功完成
# 最终结果: 任务 RobustTask_尝试2 成功完成
#
# === 超时处理 ===
# 慢协程 TimeoutTest 开始，需要 3 秒
# 任务超时！
#
# --- 使用shield防止取消 ---
# 慢协程 ShieldedTask 开始，需要 2 秒
# 外部超时，但任务继续运行...
# 被保护的任务最终完成: 慢协程 ShieldedTask 完成
```

### 5.2 协程调试技巧
```python
import asyncio
import logging

# 配置日志
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def debug_coroutine(name, duration):
    """用于调试的协程"""
    logger = logging.getLogger(f"coroutine.{name}")
    
    logger.debug(f"开始执行，预计耗时 {duration} 秒")
    
    try:
        await asyncio.sleep(duration)
        
        # 模拟可能的错误
        if duration > 2:
            raise ValueError(f"任务 {name} 耗时过长!")
        
        logger.info(f"成功完成")
        return f"{name}_结果"
        
    except Exception as e:
        logger.error(f"执行失败: {e}")
        raise

async def monitor_tasks():
    """监控任务状态"""
    print("=== 协程调试和监控 ===")
    
    # 创建多个任务
    tasks = [
        asyncio.create_task(debug_coroutine(f"Task{i}", i))
        for i in range(1, 5)
    ]
    
    # 定期检查任务状态
    while tasks:
        print(f"\n任务状态检查:")
        for i, task in enumerate(tasks):
            status = "完成" if task.done() else "运行中"
            if task.done():
                if task.exception():
                    status = f"异常: {task.exception()}"
                else:
                    status = f"完成: {task.result()}"
            print(f"  任务 {i}: {status}")
        
        # 等待一段时间或任务完成
        done, pending = await asyncio.wait(tasks, timeout=1.0, return_when=asyncio.FIRST_COMPLETED)
        
        # 移除已完成的任务
        tasks = list(pending)
        
        if done:
            print(f"本轮完成 {len(done)} 个任务")
    
    print("所有任务完成")

def enable_debug_mode():
    """启用调试模式"""
    # 设置事件循环的调试模式
    loop = asyncio.get_event_loop()
    loop.set_debug(True)
    
    # 配置日志记录器
    logging.getLogger('asyncio').setLevel(logging.DEBUG)

async def structured_logging_demo():
    """结构化日志演示"""
    print("\n=== 结构化日志 ===")
    
    logger = logging.getLogger("structured")
    
    tasks = []
    for i in range(3):
        task = asyncio.create_task(debug_coroutine(f"LogTask{i}", i))
        tasks.append(task)
        
        # 记录任务创建
        logger.info("任务创建", extra={
            'task_id': f"LogTask{i}",
            'duration': i,
            'action': 'created'
        })
    
    # 等待所有任务完成
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error("任务失败", extra={
                'task_id': f"LogTask{i}",
                'error': str(result),
                'action': 'failed'
            })
        else:
            logger.info("任务成功", extra={
                'task_id': f"LogTask{i}",
                'result': result,
                'action': 'succeeded'
            })

if __name__ == "__main__":
    # 启用调试模式
    enable_debug_mode()
    
    # 运行演示
    asyncio.run(monitor_tasks())
    asyncio.run(structured_logging_demo())

# 输出示例：
# === 协程调试和监控 ===
#
# 任务状态检查:
#   任务 0: 运行中
#   任务 1: 运行中
#   任务 2: 运行中
#   任务 3: 运行中
# 本轮完成 1 个任务
#
# 任务状态检查:
#   任务 0: 完成: Task1_结果
#   任务 1: 运行中
#   任务 2: 运行中
#   任务 3: 运行中
# ...（后续输出）
# 所有任务完成
#
# === 结构化日志 ===
# 2024-01-01 10:00:00 - structured - INFO - 任务创建
# 2024-01-01 10:00:00 - coroutine.LogTask0 - DEBUG - 开始执行，预计耗时 0 秒
# ...（后续日志输出）
```

## 6. 实际应用场景

### 6.1 异步Web请求
```python
import asyncio
import aiohttp
import time
import json

async def fetch_url(session, url, request_id):
    """获取URL内容"""
    print(f"[请求 {request_id}] 开始获取: {url}")
    
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
            content = await response.text()
            print(f"[请求 {request_id}] 完成，状态码: {response.status}, 长度: {len(content)}")
            return {
                'request_id': request_id,
                'url': url,
                'status': response.status,
                'content_length': len(content),
                'success': True
            }
    except Exception as e:
        print(f"[请求 {request_id}] 失败: {e}")
        return {
            'request_id': request_id,
            'url': url,
            'status': None,
            'error': str(e),
            'success': False
        }

async def batch_web_requests(urls, concurrent_limit=5):
    """批量Web请求"""
    print("=== 异步Web请求 ===")
    
    # 创建连接池
    connector = aiohttp.TCPConnector(limit=concurrent_limit)
    
    async with aiohttp.ClientSession(connector=connector) as session:
        # 创建所有任务
        tasks = []
        for i, url in enumerate(urls):
            task = asyncio.create_task(fetch_url(session, url, i))
            tasks.append(task)
        
        # 等待所有任务完成
        results = await asyncio.gather(*tasks)
        
        # 统计结果
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        
        print(f"\n请求统计: 成功 {successful}, 失败 {failed}")
        
        return results

async def rate_limited_requests(urls, requests_per_second=2):
    """限流的Web请求"""
    print("\n=== 限流Web请求 ===")
    
    # 创建限流器
    limiter = asyncio.Semaphore(requests_per_second)
    
    async def limited_fetch(session, url, request_id):
        async with limiter:
            # 在限流内执行请求
            result = await fetch_url(session, url, request_id)
            # 控制请求速率
            await asyncio.sleep(1 / requests_per_second)
            return result
    
    connector = aiohttp.TCPConnector(limit=requests_per_second)
    
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        for i, url in enumerate(urls):
            task = asyncio.create_task(limited_fetch(session, url, i))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def web_requests_demo():
    """Web请求演示"""
    # 测试URL列表
    test_urls = [
        "https://httpbin.org/get",
        "https://httpbin.org/delay/1",  # 延迟1秒
        "https://httpbin.org/delay/2",  # 延迟2秒
        "https://httpbin.org/status/200",
        "https://httpbin.org/status/404",
        "https://httpbin.org/status/500",
    ] * 2  # 重复一次以增加数量
    
    print(f"总共 {len(test_urls)} 个请求")
    
    # 普通批量请求
    start_time = time.time()
    results = await batch_web_requests(test_urls, concurrent_limit=3)
    normal_duration = time.time() - start_time
    print(f"普通批量请求耗时: {normal_duration:.2f}秒")
    
    # 限流请求
    start_time = time.time()
    results = await rate_limited_requests(test_urls[:6], requests_per_second=2)
    rate_limited_duration = time.time() - start_time
    print(f"限流请求耗时: {rate_limited_duration:.2f}秒")

if __name__ == "__main__":
    # 注意：需要安装aiohttp: pip install aiohttp
    asyncio.run(web_requests_demo())

# 输出示例：
# === 异步Web请求 ===
# 总共 12 个请求
# [请求 0] 开始获取: https://httpbin.org/get
# [请求 1] 开始获取: https://httpbin.org/delay/1
# [请求 2] 开始获取: https://httpbin.org/delay/2
# [请求 0] 完成，状态码: 200, 长度: 267
# [请求 3] 开始获取: https://httpbin.org/status/200
# [请求 1] 完成，状态码: 200, 长度: 402
# ...（后续输出）
# 请求统计: 成功 12, 失败 0
# 普通批量请求耗时: 6.23秒
#
# === 限流Web请求 ===
# [请求 0] 开始获取: https://httpbin.org/get
# [请求 1] 开始获取: https://httpbin.org/delay/1
# [请求 0] 完成，状态码: 200, 长度: 267
# [请求 2] 开始获取: https://httpbin.org/delay/2
# ...（每秒最多2个请求）
# 限流请求耗时: 3.15秒
```

### 6.2 异步文件操作
```python
import asyncio
import aiofiles
import os
import time

async def async_file_operations():
    """异步文件操作演示"""
    print("=== 异步文件操作 ===")
    
    # 创建测试文件
    test_data = [f"这是第{i}行数据\n" for i in range(100)]
    test_filename = "test_async_file.txt"
    
    # 异步写入文件
    print("--- 异步写入文件 ---")
    start_time = time.time()
    
    async with aiofiles.open(test_filename, 'w', encoding='utf-8') as f:
        for i, line in enumerate(test_data):
            await f.write(line)
            if i % 20 == 0:
                print(f"已写入 {i+1} 行")
    
    write_time = time.time() - start_time
    print(f"写入完成，耗时: {write_time:.2f}秒")
    
    # 异步读取文件
    print("\n--- 异步读取文件 ---")
    start_time = time.time()
    
    async with aiofiles.open(test_filename, 'r', encoding='utf-8') as f:
        content = await f.read()
        lines = content.splitlines()
    
    read_time = time.time() - start_time
    print(f"读取完成，行数: {len(lines)}，耗时: {read_time:.2f}秒")
    
    # 异步逐行读取
    print("\n--- 异步逐行读取 ---")
    start_time = time.time()
    
    async with aiofiles.open(test_filename, 'r', encoding='utf-8') as f:
        line_count = 0
        async for line in f:
            line_count += 1
            if line_count % 25 == 0:
                print(f"已读取 {line_count} 行")
    
    async_read_time = time.time() - start_time
    print(f"逐行读取完成，总行数: {line_count}，耗时: {async_read_time:.2f}秒")
    
    # 清理测试文件
    os.remove(test_filename)
    
    return {
        'write_time': write_time,
        'read_time': read_time,
        'async_read_time': async_read_time
    }

async def process_multiple_files():
    """处理多个文件"""
    print("\n=== 处理多个文件 ===")
    
    # 创建多个测试文件
    file_contents = {
        f"file_{i}.txt": [f"文件{i}的第{j}行\n" for j in range(50)]
        for i in range(5)
    }
    
    # 异步写入所有文件
    async def write_file(filename, lines):
        async with aiofiles.open(filename, 'w', encoding='utf-8') as f:
            for line in lines:
                await f.write(line)
        return f"已写入 {filename}"
    
    # 并发写入多个文件
    write_tasks = []
    for filename, lines in file_contents.items():
        task = asyncio.create_task(write_file(filename, lines))
        write_tasks.append(task)
    
    write_results = await asyncio.gather(*write_tasks)
    for result in write_results:
        print(result)
    
    # 并发读取多个文件
    async def read_file(filename):
        async with aiofiles.open(filename, 'r', encoding='utf-8') as f:
            content = await f.read()
        return len(content.splitlines())
    
    read_tasks = []
    for filename in file_contents.keys():
        task = asyncio.create_task(read_file(filename))
        read_tasks.append(task)
    
    read_results = await asyncio.gather(*read_tasks)
    for filename, line_count in zip(file_contents.keys(), read_results):
        print(f"{filename}: {line_count} 行")
    
    # 清理文件
    for filename in file_contents.keys():
        os.remove(filename)
    
    print("多文件处理完成")

if __name__ == "__main__":
    # 注意：需要安装aiofiles: pip install aiofiles
    results = asyncio.run(async_file_operations())
    asyncio.run(process_multiple_files())

# 输出示例：
# === 异步文件操作 ===
# --- 异步写入文件 ---
# 已写入 1 行
# 已写入 21 行
# 已写入 41 行
# 已写入 61 行
# 已写入 81 行
# 写入完成，耗时: 0.15秒
#
# --- 异步读取文件 ---
# 读取完成，行数: 100，耗时: 0.02秒
#
# --- 异步逐行读取 ---
# 已读取 25 行
# 已读取 50 行
# 已读取 75 行
# 已读取 100 行
# 逐行读取完成，总行数: 100，耗时: 0.03秒
#
# === 处理多个文件 ===
# 已写入 file_0.txt
# 已写入 file_1.txt
# 已写入 file_2.txt
# 已写入 file_3.txt
# 已写入 file_4.txt
# file_0.txt: 50 行
# file_1.txt: 50 行
# file_2.txt: 50 行
# file_3.txt: 50 行
# file_4.txt: 50 行
# 多文件处理完成
```

## 7. 性能优化和最佳实践

### 7.1 协程性能优化
```python
import asyncio
import time
import random

async def optimized_coroutine(task_id, use_optimizations=True):
    """优化的协程示例"""
    start_time = asyncio.get_event_loop().time()
    
    if use_optimizations:
        # 优化1：批量操作而不是单个操作
        results = []
        for i in range(10):
            # 模拟一些工作
            await asyncio.sleep(0.01)
            results.append(i)
        
        # 优化2：使用本地变量减少属性查找
        local_results = results
        total = sum(local_results)
        
    else:
        # 非优化版本
        total = 0
        for i in range(10):
            await asyncio.sleep(0.01)
            total += i
    
    end_time = asyncio.get_event_loop().time()
    duration = end_time - start_time
    
    return {
        'task_id': task_id,
        'result': total,
        'duration': duration,
        'optimized': use_optimizations
    }

class AsyncCache:
    """异步缓存"""
    
    def __init__(self, ttl=60):
        self._cache = {}
        self._ttl = ttl
        self._lock = asyncio.Lock()
    
    async def get(self, key, default=None):
        """获取缓存值"""
        async with self._lock:
            if key in self._cache:
                value, timestamp = self._cache[key]
                if time.time() - timestamp < self._ttl:
                    return value
                else:
                    # 过期删除
                    del self._cache[key]
            return default
    
    async def set(self, key, value):
        """设置缓存值"""
        async with self._lock:
            self._cache[key] = (value, time.time())
    
    async def get_or_set(self, key, coroutine_func, *args):
        """获取或设置缓存值"""
        cached_value = await self.get(key)
        if cached_value is not None:
            return cached_value
        
        # 执行协程函数获取值
        value = await coroutine_func(*args)
        await self.set(key, value)
        return value

async def expensive_operation(operation_id):
    """昂贵的操作（模拟）"""
    print(f"执行昂贵操作 {operation_id}")
    await asyncio.sleep(1)  # 模拟耗时操作
    result = f"操作_{operation_id}_结果"
    return result

async def performance_comparison():
    """性能比较"""
    print("=== 协程性能优化 ===")
    
    # 测试优化效果
    tasks_optimized = []
    tasks_normal = []
    
    for i in range(5):
        task_opt = asyncio.create_task(optimized_coroutine(f"Opt{i}", True))
        task_norm = asyncio.create_task(optimized_coroutine(f"Norm{i}", False))
        
        tasks_optimized.append(task_opt)
        tasks_normal.append(task_norm)
    
    results_opt = await asyncio.gather(*tasks_optimized)
    results_norm = await asyncio.gather(*tasks_normal)
    
    total_opt = sum(r['duration'] for r in results_opt)
    total_norm = sum(r['duration'] for r in results_norm)
    
    print(f"优化版本总耗时: {total_opt:.2f}秒")
    print(f"普通版本总耗时: {total_norm:.2f}秒")
    print(f"性能提升: {((total_norm - total_opt) / total_norm * 100):.1f}%")

async def cache_demo():
    """缓存演示"""
    print("\n=== 异步缓存 ===")
    
    cache = AsyncCache(ttl=5)  # 5秒TTL
    
    # 第一次调用，会执行昂贵操作
    print("第一次调用（缓存未命中）:")
    start_time = time.time()
    result1 = await cache.get_or_set("op1", expensive_operation, "A")
    duration1 = time.time() - start_time
    print(f"结果: {result1}, 耗时: {duration1:.2f}秒")
    
    # 第二次调用，从缓存获取
    print("\n第二次调用（缓存命中）:")
    start_time = time.time()
    result2 = await cache.get_or_set("op1", expensive_operation, "A")
    duration2 = time.time() - start_time
    print(f"结果: {result2}, 耗时: {duration2:.2f}秒")
    
    # 等待缓存过期
    print("\n等待缓存过期...")
    await asyncio.sleep(6)
    
    # 第三次调用，缓存已过期
    print("第三次调用（缓存过期）:")
    start_time = time.time()
    result3 = await cache.get_or_set("op1", expensive_operation, "A")
    duration3 = time.time() - start_time
    print(f"结果: {result3}, 耗时: {duration3:.2f}秒")

async def resource_management():
    """资源管理最佳实践"""
    print("\n=== 资源管理 ===")
    
    async def properly_managed_resource():
        """正确管理的资源"""
        print("获取资源...")
        await asyncio.sleep(0.5)
        
        try:
            print("使用资源...")
            await asyncio.sleep(0.5)
            return "操作成功"
        finally:
            print("清理资源...")
            await asyncio.sleep(0.2)
    
    async def poorly_managed_resource():
        """管理不当的资源"""
        print("获取资源...")
        await asyncio.sleep(0.5)
        
        print("使用资源...")
        await asyncio.sleep(0.5)
        
        # 注意：这里没有清理资源！
        return "操作成功但资源泄漏"
    
    print("--- 正确管理 ---")
    result1 = await properly_managed_resource()
    print(f"结果: {result1}")
    
    print("\n--- 管理不当 ---")
    result2 = await poorly_managed_resource()
    print(f"结果: {result2}")

if __name__ == "__main__":
    asyncio.run(performance_comparison())
    asyncio.run(cache_demo())
    asyncio.run(resource_management())

# 输出示例：
# === 协程性能优化 ===
# 优化版本总耗时: 0.55秒
# 普通版本总耗时: 0.60秒
# 性能提升: 8.3%
#
# === 异步缓存 ===
# 第一次调用（缓存未命中）:
# 执行昂贵操作 A
# 结果: 操作_A_结果, 耗时: 1.00秒
#
# 第二次调用（缓存命中）:
# 结果: 操作_A_结果, 耗时: 0.00秒
#
# 等待缓存过期...
# 第三次调用（缓存过期）:
# 执行昂贵操作 A
# 结果: 操作_A_结果, 耗时: 1.00秒
#
# === 资源管理 ===
# --- 正确管理 ---
# 获取资源...
# 使用资源...
# 清理资源...
# 结果: 操作成功
#
# --- 管理不当 ---
# 获取资源...
# 使用资源...
# 结果: 操作成功但资源泄漏
```

这个超详细的Python协程编程笔记涵盖了：

1. 协程基础概念和与线程/进程的比较
2. asyncio事件循环和基本用法
3. 异步控制流（迭代器、上下文管理器）
4. 高级协程模式（生产者-消费者、限流器）
5. 错误处理和调试技巧
6. 实际应用场景（Web请求、文件操作）
7. 性能优化和最佳实践

每个概念都配有详细的代码示例和注释，输出结果以注释形式展示，适合系统学习Python异步编程和协程。