
## 1. 文件操作基础概念

### 1.1 文件的基本概念

```python
# ========== 什么是文件 ==========
"""
文件是存储在外部介质（如硬盘）上的数据集合
在Python中，文件操作主要包括：
1. 打开文件
2. 读取/写入文件
3. 关闭文件
"""

# ========== 文件路径 ==========
import os

# 绝对路径
absolute_path = "/home/user/documents/example.txt"  # Linux/Mac
absolute_path_win = "C:\\Users\\user\\documents\\example.txt"  # Windows

# 相对路径
relative_path = "data/example.txt"  # 相对于当前工作目录
parent_dir = "../documents/example.txt"  # 父目录

# 获取当前工作目录
current_dir = os.getcwd()
print(f"当前工作目录: {current_dir}")

# 路径拼接（推荐使用）
file_path = os.path.join("data", "subfolder", "example.txt")
print(f"拼接后的路径: {file_path}")

# ========== 文件类型 ==========
"""
文本文件：包含可读字符，如 .txt, .py, .html
二进制文件：包含字节数据，如 .jpg, .pdf, .exe
"""

# 检查文件类型
def check_file_type(filename):
    """检查文件类型"""
    if filename.endswith(('.txt', '.py', '.html', '.csv')):
        return "文本文件"
    elif filename.endswith(('.jpg', '.png', '.pdf', '.exe')):
        return "二进制文件"
    else:
        return "未知类型"

print(f"example.txt 是: {check_file_type('example.txt')}")
print(f"image.jpg 是: {check_file_type('image.jpg')}")
```

### 1.2 文件编码

```python
# ========== 字符编码 ==========
"""
编码是将字符转换为字节的过程，常见编码：
- UTF-8: 最常用，支持所有Unicode字符
- GBK: 中文编码
- ASCII: 仅支持英文字符
- ISO-8859-1: 拉丁字母编码
"""

# 编码示例
text = "Hello, 世界！"

# 编码为字节
utf8_bytes = text.encode('utf-8')
gbk_bytes = text.encode('gbk')

print(f"UTF-8 编码: {utf8_bytes}")
print(f"GBK 编码: {gbk_bytes}")

# 解码为字符串
decoded_utf8 = utf8_bytes.decode('utf-8')
decoded_gbk = gbk_bytes.decode('gbk')

print(f"UTF-8 解码: {decoded_utf8}")
print(f"GBK 解码: {decoded_gbk}")

# ========== 编码错误处理 ==========
# 处理编码错误
try:
    # 尝试用错误编码解码
    wrong_decode = utf8_bytes.decode('ascii')
except UnicodeDecodeError as e:
    print(f"解码错误: {e}")

# 使用错误处理参数
ignore_result = utf8_bytes.decode('ascii', errors='ignore')
replace_result = utf8_bytes.decode('ascii', errors='replace')
print(f"忽略错误: {ignore_result}")
print(f"替换错误: {replace_result}")

# ========== 检测文件编码 ==========
import chardet

def detect_encoding(file_path):
    """检测文件编码"""
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            return result['encoding'], result['confidence']
    except FileNotFoundError:
        return None, 0

# 示例：检测文件编码
# encoding, confidence = detect_encoding('example.txt')
# print(f"文件编码: {encoding}, 置信度: {confidence}")
```

## 2. 文件打开和关闭

### 2.1 打开文件

```python
# ========== open() 函数 ==========
"""
open(file, mode='r', buffering=-1, encoding=None, 
     errors=None, newline=None, closefd=True, opener=None)
"""

# 基本打开方式
file = open('example.txt', 'r')  # 只读模式
content = file.read()
file.close()

# ========== 文件打开模式 ==========
"""
模式字符：
r: 只读（默认）
w: 只写，会覆盖已有文件
x: 创建新文件，如果文件已存在则失败
a: 追加，在文件末尾添加内容
b: 二进制模式
t: 文本模式（默认）
+: 更新（可读可写）
"""

# 各种模式示例
try:
    # 只读模式
    file_r = open('example.txt', 'r')  # 文本只读
    
    # 只写模式（覆盖）
    file_w = open('example.txt', 'w')  # 文本只写
    
    # 追加模式
    file_a = open('example.txt', 'a')  # 文本追加
    
    # 二进制只读
    file_rb = open('image.jpg', 'rb')  # 二进制只读
    
    # 读写模式
    file_rplus = open('example.txt', 'r+')  # 文本读写
    file_wplus = open('example.txt', 'w+')  # 文本读写，覆盖
    file_aplus = open('example.txt', 'a+')  # 文本读写，追加
    
except FileNotFoundError:
    print("文件不存在")
finally:
    # 关闭所有文件
    files = [f for f in locals() if f.startswith('file_')]
    for f in files:
        if 'file' in locals():
            eval(f).close()

# ========== 模式组合详解 ==========
def explain_mode(mode):
    """解释文件模式"""
    modes = {
        'r': '只读，文件必须存在',
        'w': '只写，创建新文件或覆盖已有文件',
        'x': '创建，文件必须不存在',
        'a': '追加，在文件末尾写入',
        'b': '二进制模式',
        't': '文本模式',
        '+': '更新（可读可写）'
    }
    
    explanation = []
    for char in mode:
        if char in modes:
            explanation.append(modes[char])
    
    return ' + '.join(explanation)

# 测试各种模式
test_modes = ['r', 'w', 'a', 'rb', 'w+', 'a+', 'x']
for mode in test_modes:
    print(f"模式 '{mode}': {explain_mode(mode)}")
```

### 2.2 关闭文件

```python
# ========== 关闭文件的重要性 ==========
"""
为什么必须关闭文件：
1. 释放系统资源
2. 确保数据完全写入磁盘
3. 避免文件被其他程序使用时出现冲突
"""

# ========== 关闭文件的方法 ==========
# 方法1：显式关闭
file = open('example.txt', 'w')
try:
    file.write("Hello, World!")
finally:
    file.close()  # 确保文件被关闭

# 方法2：使用with语句（推荐）
with open('example.txt', 'w') as file:
    file.write("Hello, World!")
# 文件会自动关闭

# ========== 检查文件是否关闭 ==========
file = open('example.txt', 'r')
print(f"文件是否关闭: {file.closed}")  # False
file.close()
print(f"文件是否关闭: {file.closed}")  # True

# ========== 文件关闭的常见错误 ==========
# 错误1：忘记关闭文件
def bad_practice():
    file = open('example.txt', 'w')
    file.write("一些内容")
    # 忘记调用 file.close()

# 错误2：在异常情况下文件未关闭
def risky_practice():
    file = open('example.txt', 'w')
    try:
        # 可能发生异常的操作
        file.write("一些内容")
        # 如果这里发生异常，file.close() 不会执行
        risky_operation()
    finally:
        file.close()  # 改进：在finally中关闭

def risky_operation():
    # 模拟可能失败的操作
    pass

# 最佳实践：总是使用with语句
def good_practice():
    with open('example.txt', 'w') as file:
        file.write("一些内容")
    # 文件自动关闭，即使发生异常
```

### 2.3 with语句和上下文管理器

```python
# ========== with语句的基本用法 ==========
# 基本语法
with open('example.txt', 'r') as file:
    content = file.read()
    print(content)
# 文件自动关闭

# ========== 多个文件同时打开 ==========
with open('input.txt', 'r') as input_file, open('output.txt', 'w') as output_file:
    content = input_file.read()
    output_file.write(content.upper())

# ========== 自定义上下文管理器 ==========
class FileManager:
    """自定义文件管理器"""
    def __init__(self, filename, mode):
        self.filename = filename
        self.mode = mode
        self.file = None
    
    def __enter__(self):
        self.file = open(self.filename, self.mode)
        print(f"打开文件: {self.filename}")
        return self.file
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.file:
            self.file.close()
            print(f"关闭文件: {self.filename}")
        if exc_type:
            print(f"发生错误: {exc_val}")
        return False  # 不抑制异常

# 使用自定义上下文管理器
with FileManager('example.txt', 'w') as f:
    f.write("使用自定义上下文管理器")

# ========== contextlib模块 ==========
from contextlib import contextmanager

@contextmanager
def open_file(filename, mode):
    """使用contextmanager装饰器创建上下文管理器"""
    file = open(filename, mode)
    try:
        print(f"打开文件: {filename}")
        yield file
    finally:
        file.close()
        print(f"关闭文件: {filename}")

# 使用contextmanager
with open_file('example.txt', 'w') as f:
    f.write("使用contextmanager")
```

## 3. 文件读取操作

### 3.1 基本读取方法

```python
# ========== read() 方法 ==========
def read_entire_file(filename):
    """读取整个文件内容"""
    with open(filename, 'r', encoding='utf-8') as file:
        content = file.read()
        return content

# 示例
# content = read_entire_file('example.txt')
# print(content)

# ========== readline() 方法 ==========
def read_line_by_line(filename):
    """逐行读取文件"""
    with open(filename, 'r', encoding='utf-8') as file:
        lines = []
        while True:
            line = file.readline()
            if not line:  # 空字符串表示文件结束
                break
            lines.append(line.strip())  # 去除换行符
        return lines

# ========== readlines() 方法 ==========
def read_all_lines(filename):
    """读取所有行到列表"""
    with open(filename, 'r', encoding='utf-8') as file:
        lines = file.readlines()
        # 去除每行的换行符
        return [line.strip() for line in lines]

# ========== 遍历文件对象 ==========
def iterate_file(filename):
    """直接遍历文件对象（推荐）"""
    with open(filename, 'r', encoding='utf-8') as file:
        for line_num, line in enumerate(file, 1):
            print(f"{line_num}: {line.strip()}")

# ========== 读取指定大小 ==========
def read_in_chunks(filename, chunk_size=1024):
    """分块读取大文件"""
    with open(filename, 'r', encoding='utf-8') as file:
        while True:
            chunk = file.read(chunk_size)
            if not chunk:
                break
            # 处理每个块
            print(f"读取 {len(chunk)} 字符")
            yield chunk

# 使用生成器处理大文件
# for chunk in read_in_chunks('large_file.txt'):
#     process_chunk(chunk)
```

### 3.2 高级读取技巧

```python
# ========== 处理大文件的内存高效方法 ==========
def process_large_file(filename):
    """处理大文件的内存高效方法"""
    with open(filename, 'r', encoding='utf-8') as file:
        for line in file:
            # 逐行处理，不一次性加载到内存
            processed_line = line.strip().upper()
            # 处理每一行
            yield processed_line

# ========== 读取特定行 ==========
def read_specific_lines(filename, line_numbers):
    """读取特定行号的内容"""
    with open(filename, 'r', encoding='utf-8') as file:
        lines = []
        for line_num, line in enumerate(file, 1):
            if line_num in line_numbers:
                lines.append((line_num, line.strip()))
        return lines

# ========== 使用enumerate获取行号 ==========
def read_with_line_numbers(filename):
    """带行号读取文件"""
    with open(filename, 'r', encoding='utf-8') as file:
        for line_number, line in enumerate(file, 1):
            print(f"{line_number:3d}: {line.rstrip()}")

# ========== 条件读取 ==========
def read_with_condition(filename, condition_func):
    """根据条件读取行"""
    with open(filename, 'r', encoding='utf-8') as file:
        for line in file:
            if condition_func(line):
                yield line.strip()

# 示例：只读取包含特定关键词的行
# keyword = 'Python'
# for line in read_with_condition('example.txt', lambda x: keyword in x):
#     print(line)

# ========== 读取CSV文件 ==========
def read_csv_basic(filename):
    """基本CSV文件读取"""
    with open(filename, 'r', encoding='utf-8') as file:
        for line in file:
            # 简单的逗号分割
            fields = line.strip().split(',')
            print(fields)

# ========== 读取JSON文件 ==========
import json

def read_json_file(filename):
    """读取JSON文件"""
    with open(filename, 'r', encoding='utf-8') as file:
        try:
            data = json.load(file)
            return data
        except json.JSONDecodeError as e:
            print(f"JSON解析错误: {e}")
            return None

# 示例
# data = read_json_file('data.json')
# if data:
#     print(data)
```

### 3.3 文件指针操作

```python
# ========== 文件指针概念 ==========
"""
文件指针表示当前读写位置
tell(): 返回当前指针位置
seek(offset, whence): 移动指针
"""

def demonstrate_file_pointer(filename):
    """演示文件指针操作"""
    with open(filename, 'r', encoding='utf-8') as file:
        # 初始位置
        print(f"初始位置: {file.tell()}")
        
        # 读取前10个字符
        content = file.read(10)
        print(f"读取10字符后位置: {file.tell()}")
        print(f"内容: {content}")
        
        # 移动到文件开头
        file.seek(0)
        print(f"移动到开头后位置: {file.tell()}")
        
        # 移动到文件末尾
        file.seek(0, 2)  # 2表示从文件末尾
        print(f"移动到末尾后位置: {file.tell()}")

# ========== seek() 方法的whence参数 ==========
"""
whence参数：
0: 从文件开头计算（默认）
1: 从当前位置计算
2: 从文件末尾计算
"""

def seek_examples(filename):
    """seek方法示例"""
    with open(filename, 'r', encoding='utf-8') as file:
        # 从开头移动5个字符
        file.seek(5)
        print(f"从开头移动5字符: {file.tell()}")
        
        # 从当前位置移动3个字符
        file.seek(3, 1)
        print(f"从当前位置移动3字符: {file.tell()}")
        
        # 从末尾向前移动5个字符
        file.seek(-5, 2)
        print(f"从末尾向前移动5字符: {file.tell()}")

# ========== 实际应用：随机访问文件 ==========
def random_file_access(filename):
    """随机访问文件内容"""
    with open(filename, 'r', encoding='utf-8') as file:
        # 获取文件大小
        file.seek(0, 2)
        file_size = file.tell()
        print(f"文件大小: {file_size} 字节")
        
        # 读取文件中间部分
        middle = file_size // 2
        file.seek(middle)
        
        # 读取中间附近的100个字符
        file.seek(max(0, middle - 50))
        content = file.read(100)
        print(f"文件中间内容:\n{content}")

# ========== 二进制文件的指针操作 ==========
def binary_file_seek(filename):
    """二进制文件的指针操作"""
    with open(filename, 'rb') as file:
        # 读取文件头信息
        header = file.read(4)
        print(f"文件头: {header}")
        
        # 移动到特定位置读取数据
        file.seek(10)  # 移动到第10字节
        data = file.read(20)  # 读取20字节
        print(f"从第10字节读取的数据: {data}")
```

## 4. 文件写入操作

### 4.1 基本写入方法

```python
# ========== write() 方法 ==========
def basic_write(filename):
    """基本文件写入"""
    with open(filename, 'w', encoding='utf-8') as file:
        file.write("第一行内容\n")
        file.write("第二行内容\n")
        file.write("第三行内容\n")

# ========== writelines() 方法 ==========
def write_multiple_lines(filename):
    """写入多行内容"""
    lines = [
        "第一行\n",
        "第二行\n", 
        "第三行\n",
        "第四行\n"
    ]
    
    with open(filename, 'w', encoding='utf-8') as file:
        file.writelines(lines)

# ========== 追加模式写入 ==========
def append_to_file(filename):
    """追加内容到文件"""
    with open(filename, 'a', encoding='utf-8') as file:
        file.write("这是追加的内容\n")
        file.write("时间戳: 2024-01-01 12:00:00\n")

# ========== 格式化写入 ==========
def formatted_write(filename):
    """格式化写入文件"""
    data = [
        {"name": "Alice", "age": 25, "city": "New York"},
        {"name": "Bob", "age": 30, "city": "London"},
        {"name": "Charlie", "age": 35, "city": "Paris"}
    ]
    
    with open(filename, 'w', encoding='utf-8') as file:
        file.write("姓名,年龄,城市\n")  # 表头
        for person in data:
            line = f"{person['name']},{person['age']},{person['city']}\n"
            file.write(line)

# ========== 使用print函数写入文件 ==========
def print_to_file(filename):
    """使用print函数写入文件"""
    with open(filename, 'w', encoding='utf-8') as file:
        print("这是通过print写入的内容", file=file)
        print("可以像正常print一样使用", file=file)
        print(f"格式化字符串: {100 + 200}", file=file)
```

### 4.2 高级写入技巧

```python
# ========== 缓冲写入 ==========
def buffered_write(filename, data, buffer_size=1024):
    """缓冲写入大文件"""
    with open(filename, 'w', encoding='utf-8') as file:
        buffer = ""
        for item in data:
            line = f"{item}\n"
            buffer += line
            
            # 当缓冲区达到指定大小时写入
            if len(buffer) >= buffer_size:
                file.write(buffer)
                buffer = ""  # 清空缓冲区
        
        # 写入剩余内容
        if buffer:
            file.write(buffer)

# ========== 条件写入 ==========
def conditional_write(filename, data, condition_func):
    """根据条件写入数据"""
    with open(filename, 'w', encoding='utf-8') as file:
        for item in data:
            if condition_func(item):
                file.write(f"{item}\n")

# 示例：只写入偶数
# numbers = range(1, 101)
# conditional_write('even_numbers.txt', numbers, lambda x: x % 2 == 0)

# ========== 写入JSON文件 ==========
import json

def write_json_file(filename, data):
    """写入JSON文件"""
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(data, file, indent=2, ensure_ascii=False)

# 示例数据
sample_data = {
    "users": [
        {"id": 1, "name": "Alice", "email": "alice@example.com"},
        {"id": 2, "name": "Bob", "email": "bob@example.com"}
    ],
    "settings": {
        "theme": "dark",
        "language": "zh-CN"
    }
}

# write_json_file('config.json', sample_data)

# ========== 写入CSV文件 ==========
import csv

def write_csv_file(filename, data):
    """写入CSV文件"""
    with open(filename, 'w', encoding='utf-8', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["姓名", "年龄", "城市"])  # 表头
        for row in data:
            writer.writerow(row)

# 示例数据
csv_data = [
    ["Alice", 25, "New York"],
    ["Bob", 30, "London"],
    ["Charlie", 35, "Paris"]
]

# write_csv_file('people.csv', csv_data)

# ========== 日志文件写入 ==========
import datetime

def write_log(filename, message, level="INFO"):
    """写入日志文件"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] [{level}] {message}\n"
    
    with open(filename, 'a', encoding='utf-8') as file:
        file.write(log_entry)

# 示例日志
# write_log('app.log', '应用程序启动', 'INFO')
# write_log('app.log', '用户登录成功', 'INFO')
# write_log('app.log', '数据库连接失败', 'ERROR')
```

## 5. 二进制文件操作

### 5.1 二进制文件读写

```python
# ========== 二进制文件读取 ==========
def read_binary_file(filename):
    """读取二进制文件"""
    with open(filename, 'rb') as file:
        # 读取文件头（前几个字节）
        header = file.read(4)
        print(f"文件头: {header}")
        
        # 读取整个文件
        file.seek(0)  # 回到文件开头
        content = file.read()
        return content

# ========== 二进制文件写入 ==========
def write_binary_file(filename, data):
    """写入二进制文件"""
    with open(filename, 'wb') as file:
        if isinstance(data, str):
            # 如果是字符串，先编码
            data = data.encode('utf-8')
        file.write(data)

# ========== 复制二进制文件 ==========
def copy_binary_file(source, destination, chunk_size=8192):
    """复制二进制文件（支持大文件）"""
    with open(source, 'rb') as src_file:
        with open(destination, 'wb') as dest_file:
            while True:
                chunk = src_file.read(chunk_size)
                if not chunk:
                    break
                dest_file.write(chunk)

# ========== 处理图片文件 ==========
from PIL import Image
import io

def process_image_file(image_path):
    """处理图片文件"""
    try:
        # 读取图片
        with open(image_path, 'rb') as file:
            image_data = file.read()
        
        # 使用PIL处理图片
        image = Image.open(io.BytesIO(image_data))
        print(f"图片格式: {image.format}")
        print(f"图片大小: {image.size}")
        print(f"图片模式: {image.mode}")
        
        return image
    except Exception as e:
        print(f"图片处理错误: {e}")
        return None

# ========== 二进制数据序列化 ==========
import pickle

def serialize_data(filename, data):
    """使用pickle序列化数据到文件"""
    with open(filename, 'wb') as file:
        pickle.dump(data, file)

def deserialize_data(filename):
    """从文件反序列化数据"""
    with open(filename, 'rb') as file:
        return pickle.load(file)

# 示例：序列化复杂数据结构
complex_data = {
    'numbers': [1, 2, 3, 4, 5],
    'text': 'Hello, World!',
    'nested': {
        'key1': 'value1',
        'key2': [1, 2, 3]
    }
}

# serialize_data('data.pkl', complex_data)
# loaded_data = deserialize_data('data.pkl')
# print(loaded_data)
```

### 5.2 结构化二进制文件

```python
# ========== 处理结构化二进制数据 ==========
import struct

def write_binary_data(filename):
    """写入结构化二进制数据"""
    with open(filename, 'wb') as file:
        # 写入不同类型的数据
        # 格式字符串: 'i'表示整数, 'f'表示浮点数, '10s'表示10字节字符串
        data_format = 'i f 10s'
        
        # 打包数据
        packed_data = struct.pack(data_format, 100, 3.14, b'Hello')
        file.write(packed_data)

def read_binary_data(filename):
    """读取结构化二进制数据"""
    with open(filename, 'rb') as file:
        # 读取并解包数据
        data_format = 'i f 10s'
        data_size = struct.calcsize(data_format)
        
        packed_data = file.read(data_size)
        if packed_data:
            unpacked_data = struct.unpack(data_format, packed_data)
            return unpacked_data
    return None

# ========== 二进制文件格式检测 ==========
def detect_file_format(filename):
    """通过文件头检测文件格式"""
    file_signatures = {
        b'\xFF\xD8\xFF': 'JPEG',
        b'\x89PNG\r\n\x1a\n': 'PNG',
        b'GIF8': 'GIF',
        b'%PDF': 'PDF',
        b'PK\x03\x04': 'ZIP'
    }
    
    with open(filename, 'rb') as file:
        file_start = file.read(8)  # 读取前8个字节
        
        for signature, file_type in file_signatures.items():
            if file.startswith(signature):
                return file_type
        
        return '未知格式'

# ========== 处理ZIP文件 ==========
import zipfile

def create_zip_archive(zip_filename, files_to_zip):
    """创建ZIP压缩文件"""
    with zipfile.ZipFile(zip_filename, 'w') as zipf:
        for file_path in files_to_zip:
            # 添加文件到ZIP，使用基本文件名作为ZIP内路径
            zipf.write(file_path, arcname=os.path.basename(file_path))

def extract_zip_archive(zip_filename, extract_path):
    """解压ZIP文件"""
    with zipfile.ZipFile(zip_filename, 'r') as zipf:
        zipf.extractall(extract_path)

# 示例
# files = ['file1.txt', 'file2.txt', 'image.jpg']
# create_zip_archive('archive.zip', files)
# extract_zip_archive('archive.zip', 'extracted_files')
```

## 6. 文件操作高级技巧

### 6.1 文件锁和并发

```python
# ========== 文件锁基础 ==========
import fcntl  # Unix/Linux
import msvcrt  # Windows

def exclusive_lock_example(filename):
    """排他锁示例（Unix/Linux）"""
    try:
        with open(filename, 'r+') as file:
            # 获取排他锁
            fcntl.flock(file.fileno(), fcntl.LOCK_EX)
            
            # 执行需要排他访问的操作
            content = file.read()
            file.seek(0)
            file.write("新的内容\n" + content)
            
            # 锁会在文件关闭时自动释放
    except IOError as e:
        print(f"文件锁错误: {e}")

# ========== 临时文件 ==========
import tempfile

def temporary_file_example():
    """临时文件使用示例"""
    # 创建临时文件
    with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as temp_file:
        temp_filename = temp_file.name
        temp_file.write("临时文件内容\n")
        temp_file.write("第二行内容\n")
        
        # 回到文件开头读取
        temp_file.seek(0)
        content = temp_file.read()
        print(f"临时文件内容:\n{content}")
    
    print(f"临时文件路径: {temp_filename}")
    
    # 使用完后可以手动删除
    # os.unlink(temp_filename)

# ========== 内存映射文件 ==========
import mmap

def memory_mapped_example(filename):
    """内存映射文件示例"""
    with open(filename, 'r+b') as file:
        # 创建内存映射
        with mmap.mmap(file.fileno(), 0) as mm:
            # 像操作字符串一样操作文件内容
            if mm.find(b'search_term') != -1:
                print("找到搜索词")
            
            # 修改内容
            mm[0:5] = b'Hello'
            
            # 读取内容
            content = mm.read(100)
            print(f"读取的内容: {content}")

# ========== 文件监控 ==========
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class FileChangeHandler(FileSystemEventHandler):
    """文件变化处理器"""
    def on_modified(self, event):
        if not event.is_directory:
            print(f"文件被修改: {event.src_path}")
    
    def on_created(self, event):
        if not event.is_directory:
            print(f"文件被创建: {event.src_path}")
    
    def on_deleted(self, event):
        if not event.is_directory:
            print(f"文件被删除: {event.src_path}")

def monitor_directory(path):
    """监控目录变化"""
    event_handler = FileChangeHandler()
    observer = Observer()
    observer.schedule(event_handler, path, recursive=True)
    observer.start()
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()

# 使用示例（需要安装watchdog: pip install watchdog）
# monitor_directory('.')
```

### 6.2 性能优化和错误处理

```python
# ========== 文件操作性能优化 ==========
def efficient_large_file_processing(input_file, output_file):
    """高效处理大文件"""
    # 使用缓冲区
    buffer_size = 8192  # 8KB缓冲区
    
    with open(input_file, 'r', encoding='utf-8') as infile, \
         open(output_file, 'w', encoding='utf-8') as outfile:
        
        while True:
            chunk = infile.read(buffer_size)
            if not chunk:
                break
            
            # 处理块数据
            processed_chunk = chunk.upper()
            outfile.write(processed_chunk)

# ========== 错误处理最佳实践 ==========
def robust_file_operations():
    """健壮的文件操作"""
    filename = 'example.txt'
    
    try:
        # 尝试打开文件
        with open(filename, 'r', encoding='utf-8') as file:
            content = file.read()
            print("文件读取成功")
            
    except FileNotFoundError:
        print(f"错误: 文件 {filename} 不存在")
        
    except PermissionError:
        print(f"错误: 没有权限读取文件 {filename}")
        
    except UnicodeDecodeError as e:
        print(f"错误: 文件编码问题 - {e}")
        # 尝试其他编码
        try:
            with open(filename, 'r', encoding='latin-1') as file:
                content = file.read()
                print("使用latin-1编码读取成功")
        except Exception as e:
            print(f"备用编码也失败: {e}")
            
    except IOError as e:
        print(f"IO错误: {e}")
        
    except Exception as e:
        print(f"未知错误: {e}")
        
    else:
        print("文件操作完成，没有错误")
        
    finally:
        print("清理操作完成")

# ========== 文件操作重试机制 ==========
import time

def robust_file_write_with_retry(filename, data, max_retries=3):
    """带重试机制的文件写入"""
    for attempt in range(max_retries):
        try:
            with open(filename, 'w', encoding='utf-8') as file:
                file.write(data)
            print("文件写入成功")
            return True
            
        except IOError as e:
            print(f"写入失败 (尝试 {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # 指数退避
                print(f"等待 {wait_time} 秒后重试...")
                time.sleep(wait_time)
            else:
                print("所有重试都失败了")
                return False

# ========== 资源清理 ==========
def safe_file_operations():
    """安全的文件操作，确保资源清理"""
    file_handles = []
    
    try:
        # 打开多个文件
        for i in range(3):
            filename = f'temp_{i}.txt'
            file = open(filename, 'w')
            file_handles.append(file)
            file.write(f"文件 {i} 的内容\n")
        
        # 执行其他操作
        # ...
        
    except Exception as e:
        print(f"操作失败: {e}")
        
    finally:
        # 确保所有文件都被关闭
        for file in file_handles:
            try:
                file.close()
            except Exception as e:
                print(f"关闭文件时出错: {e}")
        
        # 清理临时文件
        for i in range(3):
            filename = f'temp_{i}.txt'
            try:
                if os.path.exists(filename):
                    os.remove(filename)
            except Exception as e:
                print(f"删除文件 {filename} 时出错: {e}")
```

## 7. 实际应用案例

### 7.1 配置文件管理

```python
# ========== INI配置文件处理 ==========
import configparser

def read_ini_config(filename):
    """读取INI配置文件"""
    config = configparser.ConfigParser()
    
    try:
        config.read(filename, encoding='utf-8')
        
        # 读取配置项
        if config.has_section('database'):
            host = config.get('database', 'host', fallback='localhost')
            port = config.getint('database', 'port', fallback=3306)
            username = config.get('database', 'username', fallback='root')
            
            return {
                'host': host,
                'port': port,
                'username': username
            }
    
    except (configparser.Error, FileNotFoundError) as e:
        print(f"配置文件错误: {e}")
        return {}

def write_ini_config(filename, config_data):
    """写入INI配置文件"""
    config = configparser.ConfigParser()
    
    # 添加配置节和选项
    config['database'] = {
        'host': config_data.get('host', 'localhost'),
        'port': str(config_data.get('port', 3306)),
        'username': config_data.get('username', 'root'),
        'password': config_data.get('password', '')
    }
    
    config['application'] = {
        'debug': str(config_data.get('debug', False)),
        'log_level': config_data.get('log_level', 'INFO')
    }
    
    with open(filename, 'w', encoding='utf-8') as configfile:
        config.write(configfile)

# ========== JSON配置文件 ==========
import json

class ConfigManager:
    """JSON配置管理器"""
    
    def __init__(self, config_file='config.json'):
        self.config_file = config_file
        self.config = self._load_config()
    
    def _load_config(self):
        """加载配置"""
        default_config = {
            'database': {
                'host': 'localhost',
                'port': 3306,
                'username': 'root'
            },
            'app': {
                'debug': False,
                'log_level': 'INFO'
            }
        }
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            # 如果文件不存在或格式错误，使用默认配置并保存
            self._save_config(default_config)
            return default_config
    
    def _save_config(self, config):
        """保存配置"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def get(self, key, default=None):
        """获取配置值"""
        keys = key.split('.')
        value = self.config
        
        try:
            for k in keys:
                value = value[k]
            return value
        except (KeyError, TypeError):
            return default
    
    def set(self, key, value):
        """设置配置值"""
        keys = key.split('.')
        config_ref = self.config
        
        # 遍历到最后一个键的父级
        for k in keys[:-1]:
            if k not in config_ref:
                config_ref[k] = {}
            config_ref = config_ref[k]
        
        # 设置值
        config_ref[keys[-1]] = value
        
        # 保存配置
        self._save_config(self.config)

# 使用示例
# config = ConfigManager()
# db_host = config.get('database.host')
# config.set('app.debug', True)
```

### 7.2 日志系统

```python
# ========== 完整的日志系统 ==========
import logging
import logging.handlers
from datetime import datetime

class FileLogger:
    """文件日志系统"""
    
    def __init__(self, name, log_file='app.log', level=logging.INFO, 
                 max_bytes=10*1024*1024, backup_count=5):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # 避免重复添加处理器
        if not self.logger.handlers:
            # 创建格式化器
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            
            # 创建文件处理器（支持轮转）
            file_handler = logging.handlers.RotatingFileHandler(
                log_file, maxBytes=max_bytes, backupCount=backup_count,
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            
            # 创建控制台处理器
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            
            # 添加处理器
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
    
    def debug(self, message):
        self.logger.debug(message)
    
    def info(self, message):
        self.logger.info(message)
    
    def warning(self, message):
        self.logger.warning(message)
    
    def error(self, message):
        self.logger.error(message)
    
    def critical(self, message):
        self.logger.critical(message)

# 使用示例
# logger = FileLogger('MyApp')
# logger.info('应用程序启动')
# logger.error('发生了一个错误')

# ========== 自定义日志格式 ==========
def setup_custom_logging():
    """设置自定义日志格式"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)-8s] %(name)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler('custom.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# 设置自定义日志
# setup_custom_logging()
# logging.info('这是自定义格式的日志')
```

## 8. 文件操作易错点和最佳实践

### 8.1 常见错误

```python
# ========== 文件操作常见错误 ==========

# 错误1：忘记关闭文件
def bad_file_operation():
    file = open('example.txt', 'w')
    file.write("一些内容")
    # 忘记调用 file.close() - 文件可能不会完全写入，资源泄漏

# 错误2：使用错误的编码
def wrong_encoding_example():
    try:
        # 假设文件是GBK编码，但用UTF-8读取
        with open('gbk_file.txt', 'r', encoding='utf-8') as f:
            content = f.read()  # UnicodeDecodeError
    except UnicodeDecodeError as e:
        print(f"编码错误: {e}")

# 错误3：文件路径问题
def path_problems():
    # 使用硬编码路径（不可移植）
    file = open('C:\\Users\\username\\file.txt', 'r')  # Windows
    file = open('/home/username/file.txt', 'r')  # Linux
    
    # 更好的做法：使用os.path.join
    path = os.path.join('data', 'subfolder', 'file.txt')

# 错误4：不检查文件是否存在
def risky_file_read(filename):
    # 不检查文件是否存在
    with open(filename, 'r') as f:  # 如果文件不存在会抛出FileNotFoundError
        return f.read()

# 错误5：并发访问问题
def concurrent_access_issue():
    # 多个进程/线程同时写入同一个文件
    # 可能导致数据损坏或不一致
    pass

# 错误6：处理大文件时内存不足
def memory_hog(filename):
    with open(filename, 'r') as f:
        content = f.read()  # 如果文件很大，可能耗尽内存
        # 应该使用逐行读取或分块读取

# 错误7：不处理权限问题
def permission_issue():
    try:
        with open('/root/system_file', 'r') as f:  # 可能没有权限
            content = f.read()
    except PermissionError as e:
        print(f"权限错误: {e}")
```

### 8.2 最佳实践

```python
# ========== 文件操作最佳实践 ==========

# 实践1：总是使用with语句
def best_practice_with():
    with open('example.txt', 'r', encoding='utf-8') as file:
        content = file.read()
    # 文件自动关闭

# 实践2：明确指定编码
def specify_encoding():
    with open('example.txt', 'r', encoding='utf-8') as file:
        content = file.read()

# 实践3：使用os.path处理路径
def handle_paths_correctly():
    base_dir = 'data'
    filename = 'example.txt'
    file_path = os.path.join(base_dir, filename)
    
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()

# 实践4：检查文件是否存在和权限
def safe_file_operations(filename):
    if not os.path.exists(filename):
        print(f"文件不存在: {filename}")
        return None
    
    if not os.access(filename, os.R_OK):
        print(f"没有读取权限: {filename}")
        return None
    
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            return file.read()
    except Exception as e:
        print(f"读取文件时出错: {e}")
        return None

# 实践5：处理大文件时使用迭代
def process_large_file_efficiently(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        for line in file:
            process_line(line)  # 逐行处理

# 实践6：使用适当的缓冲区大小
def optimized_file_copy(source, destination, buffer_size=8192):
    with open(source, 'rb') as src, open(destination, 'wb') as dest:
        while True:
            chunk = src.read(buffer_size)
            if not chunk:
                break
            dest.write(chunk)

# 实践7：错误处理和重试
def robust_file_operation(filename, operation, max_retries=3):
    for attempt in range(max_retries):
        try:
            return operation(filename)
        except IOError as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(1)  # 等待后重试

# 实践8：使用临时文件进行原子操作
def atomic_file_write(filename, data):
    """原子文件写入，避免写入过程中出现损坏"""
    temp_filename = filename + '.tmp'
    
    try:
        # 写入临时文件
        with open(temp_filename, 'w', encoding='utf-8') as temp_file:
            temp_file.write(data)
        
        # 重命名（在大多数系统上是原子操作）
        os.replace(temp_filename, filename)
        
    finally:
        # 清理临时文件（如果存在）
        if os.path.exists(temp_filename):
            try:
                os.remove(temp_filename)
            except OSError:
                pass  # 忽略清理错误

# 实践9：使用适当的文件锁
def synchronized_file_access(filename, operation):
    """同步文件访问，避免并发问题"""
    # 这需要平台特定的实现
    # Unix/Linux: fcntl
    # Windows: msvcrt
    pass

# 实践10：记录文件操作日志
def logged_file_operation(operation_name, filename):
    """记录文件操作日志"""
    start_time = time.time()
    
    try:
        # 执行文件操作
        result = perform_operation(filename)
        
        # 记录成功日志
        duration = time.time() - start_time
        logging.info(f"{operation_name} 成功: {filename} (耗时: {duration:.2f}s)")
        
        return result
        
    except Exception as e:
        # 记录错误日志
        logging.error(f"{operation_name} 失败: {filename} - {e}")
        raise

def perform_operation(filename):
    """执行实际的文件操作"""
    # 模拟文件操作
    with open(filename, 'r') as f:
        return f.read()
```

## 总结

Python文件操作是编程中的基础且重要的部分。关键要点包括：

1. **文件打开和关闭**：总是使用`with`语句确保文件正确关闭
2. **文件模式**：理解不同模式的区别，特别是`r`、`w`、`a`和二进制模式
3. **编码处理**：明确指定文件编码，正确处理编码错误
4. **读取方法**：
   - `read()`：读取整个文件
   - `readline()`：逐行读取
   - `readlines()`：读取所有行到列表
   - 直接遍历文件对象（推荐用于大文件）

5. **写入方法**：
   - `write()`：写入字符串
   - `writelines()`：写入字符串列表
   - 格式化写入和使用`print`函数

6. **文件指针**：使用`seek()`和`tell()`进行随机访问

7. **二进制文件**：使用`'b'`模式，处理图片、序列化数据等

8. **错误处理**：妥善处理文件不存在、权限错误、编码错误等情况

9. **性能优化**：对于大文件使用迭代处理，适当设置缓冲区大小

10. **最佳实践**：
    - 使用`os.path`处理路径
    - 检查文件存在性和权限
    - 使用原子操作避免数据损坏
    - 记录文件操作日志

掌握这些文件操作技巧，可以编写出健壮、高效的Python程序来处理各种文件操作需求。